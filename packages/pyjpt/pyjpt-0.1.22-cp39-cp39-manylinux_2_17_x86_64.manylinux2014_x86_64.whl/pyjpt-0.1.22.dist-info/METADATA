Metadata-Version: 2.1
Name: pyjpt
Version: 0.1.22
Requires-Dist: dnutils (>=0.3.12)
Requires-Dist: graphviz (>=0.20.1)
Requires-Dist: scipy (>=1.10.1)
Requires-Dist: numpy (>=1.24.3)
Requires-Dist: matplotlib (>=3.7.1)
Requires-Dist: pandas (>=2.0.1)
Requires-Dist: dateparser
Requires-Dist: arff (>=0.9)
Requires-Dist: tqdm (>=4.65.0)
Requires-Dist: tabulate (>=0.9.0)
Requires-Dist: fglib (>=0.2.3)
Requires-Dist: factorgraph (>=0.0.3)
Requires-Dist: mlflow (>=2.3.1)
Requires-Dist: scikit-learn (>=1.2.0)
Requires-Dist: requests (>=2.27.1)
Requires-Dist: ddt (>=1.6.0)
Requires-Dist: plotly (>=5.7.0)
Requires-Dist: setuptools (>=47.1.1)
Requires-Dist: Cython (>=0.29.34)

Joint Probability Trees (short JPTs) are a formalism for learning of and reasoning about joint probability
distributions, which is tractable for practical applications. JPTs support both symbolic and subsymbolic variables in a single
hybrid model, and they do not rely on prior knowledge about variable dependencies or families of distributions.
JPT representations build on tree structures that partition the problem space into relevant subregions that are elicited
from the training data instead of postulating a rigid dependency model prior to learning. Learning and reasoning scale
linearly in JPTs, and the tree structure allows white-box reasoning about any posterior probability :math:`P(Q\mid E)`,
such that interpretable explanations can be provided for any inference result. This documentation introduces the
code base of the ``pyjpt`` library, which is implemented in Python/Cython, and showcases the practical
applicability of JPTs in high-dimensional heterogeneous probability spaces, making it
a promising alternative to classic probabilistic

## Documentation
The documentation is hosted on readthedocs.org [here](https://joint-probability-trees.readthedocs.io/en/latest/).
