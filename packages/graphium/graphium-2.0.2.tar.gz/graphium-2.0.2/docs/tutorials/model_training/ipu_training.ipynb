{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training on IPU from configurations\n",
    "\n",
    "This tutorial will walk you through how to use a configuration file to define all the parameters of a model and of the trainer. This tutorial focuses on training from SMILES data in a CSV format.\n",
    "\n",
    "There are multiple examples of YAML files located in the folder `graphium/expts` that one can refer to when training a new model. The file `docs/tutorials/model_training/config_ipu_tutorials.yaml` shows an example of multi-task regression from a CSV file provided by graphium.\n",
    "\n",
    "If you are not familiar with [PyTorch](https://pytorch.org/docs) or [PyTorch-Lightning](https://pytorch-lightning.readthedocs.io/en/latest/), we highly recommend going through their tutorial first."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ipu config file\n",
    "The IPU config file can be found at `expts/configs/ipu.config`. And is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deviceIterations(16)\n",
      "replicationFactor(1)\n",
      "Training.gradientAccumulation(1)    # How many gradient steps to accumulate\n",
      "modelName(\"reproduce_mixed\")        # TODO: Use the name from the main file, and add date/time\n",
      "enableProfiling(\"pro_vision\")       # The folder where the profile will be stored\n",
      "Jit.traceModel(True)\n",
      "enableExecutableCaching(\"pop_compiler_cache\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os.path import dirname, join\n",
    "import graphium\n",
    "GRAPHIUM_PATH = dirname(dirname(graphium.__file__))\n",
    "with open(join(GRAPHIUM_PATH, \"expts/configs/ipu.config\")) as f:\n",
    "    lines = f.readlines()\n",
    "print(\"\".join(lines))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the yaml file\n",
    "\n",
    "The first step is to create a YAML file containing all the required configurations, with an example given at `graphium/docs/tutorials/model_training/config_ipu_tutorials.yaml`. We will go through each part of the configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config_with_key(config, key):\n",
    "    new_config = {key: config[key]}\n",
    "    print(omegaconf.OmegaConf.to_yaml(new_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaml file loaded\n"
     ]
    }
   ],
   "source": [
    "# First, let's read the yaml configuration file\n",
    "with open(\"config_ipu_tutorials.yaml\", \"r\") as file:\n",
    "    yaml_config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "print(\"Yaml file loaded\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants\n",
    "\n",
    "First, we define the constants such as the random seed and whether the model should raise or ignore an error.\n",
    "The `name` here will be used to log the metrics into WandB and log the models.\n",
    "The `accelerator` is used to define the device. It supports `cpu`, `ipu` or `gpu`. This is the only part that needs to change when working with IPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constants:\n",
      "  name: tutorial_model\n",
      "  seed: 42\n",
      "  raise_train_error: true\n",
      "  accelerator:\n",
      "    type: ipu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"constants\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datamodule\n",
    "\n",
    "Here, we define all the parameters required by the datamodule to run correctly, such as the dataset path, whether to cache, the columns for the training, the molecular featurization to use, the train/val/test splits and the batch size.\n",
    "\n",
    "The `MultitaskFromSmilesDataModule` allows us to define a set of tasks within different CSV or parquet files, and use them to train the model simultaneously via the path `datamodule: args: task_specific_args`\n",
    "\n",
    "For more details, see class `graphium.data.datamodule.MultitaskFromSmilesDataModule`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading a CSV file and train/val/test splits\n",
    "Here is an example of configuration regarding the task named \"homo\", which reads the file located in `https://storage.googleapis.com/graphium-public/datasets/QM9/norm_mini_qm9.csv` , selects the columns \"homo\" and \"lumo\", and splits into validation and test set with rations of 20% each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo:\n",
      "  df: null\n",
      "  df_path: https://storage.googleapis.com/graphium-public/datasets/QM9/norm_micro_qm9.csv\n",
      "  smiles_col: smiles\n",
      "  label_cols:\n",
      "  - homo\n",
      "  - lumo\n",
      "  split_val: 0.2\n",
      "  split_test: 0.2\n",
      "  split_seed: 42\n",
      "  splits_path: null\n",
      "  sample_size: null\n",
      "  idx_col: null\n",
      "  weights_col: null\n",
      "  weights_type: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config[\"datamodule\"][\"args\"][\"task_specific_args\"], \"homo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Featurizing a molecule\n",
    "Molecules can be featurized using various properties and positional / structural encoding. A list of all features is available here:\n",
    "- `graphium.features.featurizer.get_mol_atomic_features_onehot`\n",
    "- `graphium.features.featurizer.get_mol_atomic_features_float`\n",
    "- `graphium.features.featurizer.get_mol_edge_features`\n",
    "- `graphium.features.spectral.compute_laplacian_positional_eigvecs`\n",
    "- `graphium.features.rw.compute_rwse`\n",
    "\n",
    "Example of a configuration for featurization below. Notice the list of atomic and edge properties. Notice `pos_encoding_as_features` that defines both the laplacian and random-walk positional encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurization:\n",
      "  atom_property_list_onehot:\n",
      "  - atomic-number\n",
      "  - valence\n",
      "  atom_property_list_float:\n",
      "  - mass\n",
      "  - electronegativity\n",
      "  - in-ring\n",
      "  edge_property_list:\n",
      "  - bond-type-onehot\n",
      "  - stereo\n",
      "  - in-ring\n",
      "  add_self_loop: false\n",
      "  explicit_H: false\n",
      "  use_bonds_weights: false\n",
      "  pos_encoding_as_features:\n",
      "    pos_types:\n",
      "      la_pos:\n",
      "        pos_type: laplacian_eigvec_eigval\n",
      "        num_pos: 3\n",
      "        normalization: none\n",
      "        disconnected_comp: true\n",
      "      rw_pos:\n",
      "        pos_type: rwse\n",
      "        ksteps: 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config[\"datamodule\"][\"args\"], \"featurization\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "In the architecture, we define all the layers for the model, including the layers for the pre-processing MLP (input layers `pre-nn`), the post-processing MLP (output layers `post-nn`), and the main GNN (graph neural network `gnn`).\n",
    "\n",
    "The parameters allow to chose the feature size, the depth, the skip connections, the pooling and the virtual node. It also support different GNN layers such as `pyg:gcn`, `pyg:gin`, `pyg:gine`,  `pyg:gated-gcn`, `pyg:pna-msgpass`, and `pyg:gps`.\n",
    "\n",
    "For more details, see the following classes:\n",
    "\n",
    "-  `graphium.nn.global_architecture.FullGraphMultiTaskNetwork`: Main class for the architecture\n",
    "-  `graphium.nn.global_architecture.FeedForwardNN`: Main class for the inputs and outputs MLP\n",
    "-  `graphium.nn.pyg_architecture.FeedForwardPyg`: Main class for the GNN layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for the node pre-processing NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_nn:\n",
      "  out_dim: 32\n",
      "  hidden_dims: 32\n",
      "  depth: 1\n",
      "  activation: relu\n",
      "  last_activation: none\n",
      "  dropout: 0.1\n",
      "  normalization: none\n",
      "  last_normalization: none\n",
      "  residual_type: none\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config[\"architecture\"], \"pre_nn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for the edge pre-processing NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_nn_edges:\n",
      "  out_dim: 16\n",
      "  hidden_dims: 16\n",
      "  depth: 1\n",
      "  activation: relu\n",
      "  last_activation: none\n",
      "  dropout: 0.1\n",
      "  normalization: none\n",
      "  last_normalization: none\n",
      "  residual_type: none\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config[\"architecture\"], \"pre_nn_edges\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for the GNN\n",
    "Here is an example of a GraphGPS layer, with it's MPNN being a GINE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn:\n",
      "  out_dim: 32\n",
      "  hidden_dims: 32\n",
      "  depth: 3\n",
      "  activation: relu\n",
      "  last_activation: none\n",
      "  dropout: 0.1\n",
      "  normalization: none\n",
      "  last_normalization: none\n",
      "  residual_type: simple\n",
      "  pooling:\n",
      "  - sum\n",
      "  - mean\n",
      "  - max\n",
      "  virtual_node: none\n",
      "  layer_type: pyg:gps\n",
      "  layer_kwargs:\n",
      "    mpnn_type: pyg:gine\n",
      "    mpnn_kwargs: null\n",
      "    attn_type: full-attention\n",
      "    attn_kwargs: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config[\"architecture\"], \"gnn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for the node post-processing NN (after the GNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_output_nn:\n",
      "  out_dim: 32\n",
      "  hidden_dims: 32\n",
      "  depth: 1\n",
      "  activation: relu\n",
      "  last_activation: none\n",
      "  dropout: 0.1\n",
      "  normalization: none\n",
      "  last_normalization: none\n",
      "  residual_type: none\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config[\"architecture\"], \"graph_output_nn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for the multi-task output heads\n",
    "Here is the example for the task heads. Notice that `\"task_name\"` should match the tasks in the section `datamodule: args: task_specific_args`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_heads:\n",
      "- task_name: homo\n",
      "  out_dim: 2\n",
      "  hidden_dims: 32\n",
      "  depth: 2\n",
      "  activation: relu\n",
      "  last_activation: none\n",
      "  dropout: 0.1\n",
      "  normalization: none\n",
      "  last_normalization: none\n",
      "  residual_type: none\n",
      "- task_name: alpha\n",
      "  out_dim: 1\n",
      "  hidden_dims: 32\n",
      "  depth: 2\n",
      "  activation: relu\n",
      "  last_activation: none\n",
      "  dropout: 0.1\n",
      "  normalization: none\n",
      "  last_normalization: none\n",
      "  residual_type: none\n",
      "- task_name: cv\n",
      "  out_dim: 1\n",
      "  hidden_dims: 32\n",
      "  depth: 2\n",
      "  activation: relu\n",
      "  last_activation: none\n",
      "  dropout: 0.1\n",
      "  normalization: none\n",
      "  last_normalization: none\n",
      "  residual_type: none\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config[\"architecture\"], \"task_heads\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor\n",
    "\n",
    "In the predictor, we define the loss functions, the metrics to track on the progress bar, and all the parameters necessary for the optimizer.\n",
    "\n",
    "Again, each of these arguments depend on the task. And the `task_name` should match the ones from `datamodule: args: task_specific_args`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor:\n",
      "  metrics_on_progress_bar:\n",
      "    homo:\n",
      "    - mae\n",
      "    - pearsonr\n",
      "    alpha:\n",
      "    - mae\n",
      "    cv:\n",
      "    - mae\n",
      "    - pearsonr\n",
      "  loss_fun:\n",
      "    homo: mse_ipu\n",
      "    alpha: mse_ipu\n",
      "    cv: mse_ipu\n",
      "  random_seed: 42\n",
      "  optim_kwargs:\n",
      "    lr: 0.001\n",
      "  torch_scheduler_kwargs: null\n",
      "  scheduler_kwargs: null\n",
      "  target_nan_mask: null\n",
      "  flag_kwargs:\n",
      "    n_steps: 0\n",
      "    alpha: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"predictor\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "All the metrics can be defined there. If we want to use a classification metric, we can also define a threshold.\n",
    "\n",
    "See class `graphium.trainer.metrics.MetricWrapper` for more details.\n",
    "\n",
    "See `graphium.trainer.metrics.METRICS_CLASSIFICATION` and `graphium.trainer.metrics.METRICS_REGRESSION` for a dictionnary of accepted metrics.\n",
    "\n",
    "Again, the metrics are task-dependant and must match the names in `datamodule: args: task_specific_args`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics:\n",
      "  homo:\n",
      "  - name: mae\n",
      "    metric: mae\n",
      "    threshold_kwargs: null\n",
      "  - name: pearsonr\n",
      "    metric: pearsonr\n",
      "    threshold_kwargs: null\n",
      "    target_nan_mask: ignore-mean-label\n",
      "  alpha:\n",
      "  - name: mae\n",
      "    metric: mae\n",
      "    threshold_kwargs: null\n",
      "  - name: pearsonr\n",
      "    metric: pearsonr\n",
      "    threshold_kwargs: null\n",
      "  cv:\n",
      "  - name: mae\n",
      "    metric: mae\n",
      "    threshold_kwargs: null\n",
      "  - name: pearsonr\n",
      "    metric: pearsonr\n",
      "    threshold_kwargs: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"metrics\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer\n",
    "\n",
    "Finally, the Trainer defines the parameters for the number of epochs to train, the checkpoints, and the patience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainer:\n",
      "  logger:\n",
      "    save_dir: logs/QM9\n",
      "    name: tutorial_model\n",
      "  model_checkpoint:\n",
      "    dirpath: models_checkpoints/QM9/\n",
      "    filename: tutorial_model\n",
      "    save_top_k: 1\n",
      "    every_n_epochs: 1\n",
      "  trainer:\n",
      "    precision: 32\n",
      "    max_epochs: 5\n",
      "    min_epochs: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_config_with_key(yaml_config, \"trainer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Now that we defined all the configuration files, we want to train the model. The steps are fairly easy using the config loaders, and are given below.\n",
    "\n",
    "### First, let's do our imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "from os.path import dirname, abspath\n",
    "import yaml\n",
    "from copy import deepcopy\n",
    "from omegaconf import DictConfig\n",
    "import timeit\n",
    "from loguru import logger\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "\n",
    "# Current project imports\n",
    "import graphium\n",
    "from graphium.config._loader import load_datamodule, load_metrics, load_architecture, load_predictor, load_trainer\n",
    "from graphium.utils.safe_run import SafeRun\n",
    "\n",
    "# WandB\n",
    "import wandb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, let's load the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the working directory\n",
    "MAIN_DIR = dirname(dirname(abspath(graphium.__file__)))\n",
    "CONFIG_FILE = \"docs/tutorials/model_training/config_ipu_tutorials.yaml\"\n",
    "os.chdir(MAIN_DIR)\n",
    "\n",
    "with open(os.path.join(MAIN_DIR, CONFIG_FILE), \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:16:35.918] [poptorch::python] [warning] trace_model=True is deprecated since version 3.0 and will be removed in a future release\n",
      "2022-09-20 17:16:35.920 | INFO     | graphium.data.datamodule:prepare_data:699 - Reading data for task 'homo'\n",
      "2022-09-20 17:16:36.462 | INFO     | graphium.data.datamodule:prepare_data:699 - Reading data for task 'alpha'\n",
      "2022-09-20 17:16:36.585 | INFO     | graphium.data.datamodule:prepare_data:699 - Reading data for task 'cv'\n",
      "2022-09-20 17:16:36.707 | INFO     | graphium.data.datamodule:prepare_data:721 - Done reading datasets\n",
      "2022-09-20 17:16:36.707 | INFO     | graphium.data.datamodule:prepare_data:733 - Prepare single-task dataset for task 'homo' with 1005 data points.\n",
      "2022-09-20 17:16:36.708 | INFO     | graphium.data.datamodule:prepare_data:733 - Prepare single-task dataset for task 'alpha' with 1005 data points.\n",
      "2022-09-20 17:16:36.709 | INFO     | graphium.data.datamodule:prepare_data:733 - Prepare single-task dataset for task 'cv' with 1005 data points.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce74314fe284fd2b066580149aa03df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mols to ids:   0%|          | 0/3015 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8d2c88b93b4d73aea5a9b61a270c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "featurizing_smiles:   0%|          | 0/1005 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and initialize the dataset\n",
    "datamodule = load_datamodule(cfg)\n",
    "datamodule.prepare_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build the architecture, metrics, and set-up the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 17:16:46.768 | INFO     | __main__:<cell line: 8>:8 - {'homo': {'mae': mean_absolute_error, 'pearsonr': pearson_corrcoef}, 'alpha': {'mae': mean_absolute_error, 'pearsonr': pearson_corrcoef}, 'cv': {'mae': mean_absolute_error, 'pearsonr': pearson_corrcoef}}\n",
      "2022-09-20 17:16:46.812 | INFO     | __main__:<cell line: 12>:12 - Multitask_GNN\n",
      "---------------\n",
      "    pre-NN(depth=1, ResidualConnectionNone)\n",
      "        [FCLayer[87 -> 32]\n",
      "    \n",
      "    pre-NN-edges(depth=1, ResidualConnectionNone)\n",
      "        [FCLayer[13 -> 16]\n",
      "    \n",
      "    GNN(depth=3, ResidualConnectionSimple(skip_steps=1))\n",
      "        GPSLayerPyg[32 -> 32 -> 32 -> 32]\n",
      "        -> Pooling(['sum', 'mean', 'max']) -> FCLayer(96 -> 32, activation=None)\n",
      "    \n",
      "    post-NN(depth=1, ResidualConnectionNone)\n",
      "        [FCLayer[32 -> 32]\n",
      "2022-09-20 17:16:46.813 | INFO     | __main__:<cell line: 13>:13 -    | Name                                | Type                      | Params\n",
      "-----------------------------------------------------------------------------------\n",
      "0  | model                               | FullGraphMultiTaskNetwork | 47.6 K\n",
      "1  | model.pe_encoders                   | ModuleDict                | 681   \n",
      "2  | model.pe_encoders.la_pos            | LapPENodeEncoder          | 137   \n",
      "3  | model.pe_encoders.la_pos.linear_A   | Linear                    | 9     \n",
      "4  | model.pe_encoders.la_pos.pe_encoder | MLP                       | 128   \n",
      "5  | model.pe_encoders.rw_pos            | MLPEncoder                | 544   \n",
      "6  | model.pe_encoders.rw_pos.pe_encoder | MLP                       | 544   \n",
      "7  | model.pre_nn                        | FeedForwardNN             | 2.8 K \n",
      "8  | model.pre_nn.activation             | ReLU                      | 0     \n",
      "9  | model.pre_nn.residual_layer         | ResidualConnectionNone    | 0     \n",
      "10 | model.pre_nn.layers                 | ModuleList                | 2.8 K \n",
      "11 | model.pre_nn.layers.0               | FCLayer                   | 2.8 K \n",
      "12 | model.pre_nn_edges                  | FeedForwardNN             | 224   \n",
      "13 | model.pre_nn_edges.activation       | ReLU                      | 0     \n",
      "14 | model.pre_nn_edges.residual_layer   | ResidualConnectionNone    | 0     \n",
      "15 | model.pre_nn_edges.layers           | ModuleList                | 224   \n",
      "16 | model.pre_nn_edges.layers.0         | FCLayer                   | 224   \n",
      "17 | model.gnn                           | FeedForwardPyg            | 39.5 K\n",
      "18 | model.gnn.activation                | ReLU                      | 0     \n",
      "19 | model.gnn.layers                    | ModuleList                | 36.4 K\n",
      "20 | model.gnn.layers.0                  | GPSLayerPyg               | 12.1 K\n",
      "21 | model.gnn.layers.1                  | GPSLayerPyg               | 12.1 K\n",
      "22 | model.gnn.layers.2                  | GPSLayerPyg               | 12.1 K\n",
      "23 | model.gnn.virtual_node_layers       | ModuleList                | 0     \n",
      "24 | model.gnn.virtual_node_layers.0     | VirtualNodePyg            | 0     \n",
      "25 | model.gnn.virtual_node_layers.1     | VirtualNodePyg            | 0     \n",
      "26 | model.gnn.residual_layer            | ResidualConnectionSimple  | 0     \n",
      "27 | model.gnn.global_pool_layer         | ModuleListConcat          | 0     \n",
      "28 | model.gnn.global_pool_layer.0       | PoolingWrapperPyg         | 0     \n",
      "29 | model.gnn.global_pool_layer.1       | PoolingWrapperPyg         | 0     \n",
      "30 | model.gnn.global_pool_layer.2       | PoolingWrapperPyg         | 0     \n",
      "31 | model.gnn.out_linear                | FCLayer                   | 3.1 K \n",
      "32 | model.gnn.out_linear.linear         | Linear                    | 3.1 K \n",
      "33 | model.gnn.out_linear.dropout        | Dropout                   | 0     \n",
      "34 | model.graph_output_nn                       | FeedForwardNN             | 1.1 K \n",
      "35 | model.graph_output_nn.activation            | ReLU                      | 0     \n",
      "36 | model.graph_output_nn.residual_layer        | ResidualConnectionNone    | 0     \n",
      "37 | model.graph_output_nn.layers                | ModuleList                | 1.1 K \n",
      "38 | model.graph_output_nn.layers.0              | FCLayer                   | 1.1 K \n",
      "39 | model.task_heads                    | TaskHeads                 | 3.3 K \n",
      "40 | model.task_heads.task_heads         | ModuleDict                | 3.3 K \n",
      "41 | model.task_heads.task_heads.homo    | TaskHead                  | 1.1 K \n",
      "42 | model.task_heads.task_heads.alpha   | TaskHead                  | 1.1 K \n",
      "43 | model.task_heads.task_heads.cv      | TaskHead                  | 1.1 K \n",
      "-----------------------------------------------------------------------------------\n",
      "47.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.6 K    Total params\n",
      "0.190     Total estimated model params size (MB)\n",
      "[17:16:46.843] [poptorch::python] [warning] trace_model=True is deprecated since version 3.0 and will be removed in a future release\n",
      "/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ipu.py:20: LightningDeprecationWarning: The `pl.plugins.training_type.ipu.IPUPlugin` is deprecated in v1.6 and will be removed in v1.8. Use `pl.strategies.ipu.IPUStrategy` instead.\n",
      "  rank_zero_deprecation(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdbeaini_mila\u001b[0m (\u001b[33mmultitask-gnn\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dom/graphium/wandb/run-20220920_171648-1ss172i9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/multitask-gnn/multitask-gnn/runs/1ss172i9\" target=\"_blank\">tutorial-run</a></strong> to <a href=\"https://wandb.ai/multitask-gnn/multitask-gnn\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:317: LightningDeprecationWarning: Passing <graphium.ipu.ipu_wrapper.IPUPluginGraphium object at 0x7f4431dfc220> `strategy` to the `plugins` flag in Trainer has been deprecated in v1.5 and will be removed in v1.7. Use `Trainer(strategy=<graphium.ipu.ipu_wrapper.IPUPluginGraphium object at 0x7f4431dfc220>)` instead.\n",
      "  rank_zero_deprecation(\n",
      "/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:469: UserWarning: more than one device specific flag has been set\n",
      "  rank_zero_warn(\"more than one device specific flag has been set\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: True, using: 1 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network\n",
    "model_class, model_kwargs = load_architecture(\n",
    "    cfg,\n",
    "    in_dims=datamodule.in_dims,\n",
    ")\n",
    "\n",
    "metrics = load_metrics(cfg)\n",
    "logger.info(metrics)\n",
    "\n",
    "predictor = load_predictor(cfg, model_class, model_kwargs, metrics)\n",
    "predictor.set_max_nodes_edges_per_graph(datamodule, stages=[\"train\", \"val\"])\n",
    "\n",
    "logger.info(predictor.model)\n",
    "logger.info(ModelSummary(predictor, max_depth=4))\n",
    "\n",
    "trainer = load_trainer(cfg, \"tutorial-run\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:326: LightningDeprecationWarning: Base `LightningModule.on_train_batch_end` hook signature has changed in v1.5. The `dataloader_idx` argument will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:154: LightningDeprecationWarning: The `LightningModule.get_progress_bar_dict` method was deprecated in v1.5 and will be removed in v1.7. Please use the `ProgressBarBase.get_metrics` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77219b518e548e9adf689f8ef764f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mols to ids:   0%|          | 0/1809 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57098a6b7fb43a197a533dea7d7babc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mols to ids:   0%|          | 0/603 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/dom/graphium/models_checkpoints/QM9 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name  | Type                      | Params\n",
      "----------------------------------------------------\n",
      "0 | model | FullGraphMultiTaskNetwork | 47.6 K\n",
      "----------------------------------------------------\n",
      "47.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.6 K    Total params\n",
      "0.190     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "MultitaskDataset\n",
      "\tabout = training set\n",
      "\tnum_graphs_total = 603\n",
      "\tnum_nodes_total = 5285\n",
      "\tmax_num_nodes_per_graph = 9\n",
      "\tmin_num_nodes_per_graph = 1\n",
      "\tstd_num_nodes_per_graph = 0.6989218547197285\n",
      "\tmean_num_nodes_per_graph = 8.764510779436153\n",
      "\tnum_edges_total = 11316\n",
      "\tmax_num_edges_per_graph = 26\n",
      "\tmin_num_edges_per_graph = 0\n",
      "\tstd_num_edges_per_graph = 2.6821780989470896\n",
      "\tmean_num_edges_per_graph = 18.766169154228855\n",
      "-------------------\n",
      "\n",
      "-------------------\n",
      "MultitaskDataset\n",
      "\tabout = validation set\n",
      "\tnum_graphs_total = 201\n",
      "\tnum_nodes_total = 1756\n",
      "\tmax_num_nodes_per_graph = 9\n",
      "\tmin_num_nodes_per_graph = 2\n",
      "\tstd_num_nodes_per_graph = 0.7949619835770694\n",
      "\tmean_num_nodes_per_graph = 8.7363184079602\n",
      "\tnum_edges_total = 3736\n",
      "\tmax_num_edges_per_graph = 24\n",
      "\tmin_num_edges_per_graph = 2\n",
      "\tstd_num_edges_per_graph = 2.7704251592456193\n",
      "\tmean_num_edges_per_graph = 18.587064676616915\n",
      "-------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74176148739249908fb1f22af5fc27c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 17:16:59.088 | INFO     | graphium.ipu.ipu_dataloader:create_ipu_dataloader:230 - Estimating pack max_pack_size=54 or max_pack_size_per_graph=9.0\n",
      "2022-09-20 17:16:59.089 | INFO     | graphium.ipu.ipu_dataloader:create_ipu_dataloader:233 - Provided `max_num_nodes=72`\n",
      "[17:17:02.052] [poptorch:cpp] [warning] Graph contains an unused input %this_input : Long(1, strides=[1], requires_grad=0, device=cpu)\n",
      "[17:17:02.054] [poptorch:cpp] [warning] %value.3 : Long(2, 144, strides=[144, 1], requires_grad=0, device=cpu) = aten::to(%tensor.1, %111, %112, %113, %114) # /home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/poptorch/_poplar_executor.py:1315:0: torch.int64 is not supported natively on IPU, loss of range/precision may occur. We will only warn on the first instance.\n",
      "Graph compilation: 100%|██████████| 100/100 [00:01<00:00]\n",
      "2022-09-20 17:17:07.541 | INFO     | graphium.ipu.ipu_dataloader:create_ipu_dataloader:230 - Estimating pack max_pack_size=54 or max_pack_size_per_graph=9.0\n",
      "2022-09-20 17:17:07.542 | INFO     | graphium.ipu.ipu_dataloader:create_ipu_dataloader:233 - Provided `max_num_nodes=72`\n",
      "/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc551a36207d46588d9f5fc85439ae4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dom/graphium/graphium/ipu/ipu_wrapper.py:274: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if all([this_input.shape[0] == 1 for this_input in inputs]):\n",
      "/home/dom/graphium/graphium/ipu/ipu_wrapper.py:307: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  batch_idx = batch.pop(\"_batch_idx\").item()\n",
      "/home/dom/graphium/graphium/nn/base_layers.py:169: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  if torch.prod(torch.as_tensor(h.shape[:-1])) == 0:\n",
      "/home/dom/graphium/graphium/nn/base_layers.py:169: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if torch.prod(torch.as_tensor(h.shape[:-1])) == 0:\n",
      "/home/dom/graphium/graphium/nn/architectures/pyg_architectures.py:139: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert node_feats.shape[0] == g.num_nodes\n",
      "/home/dom/graphium/graphium/nn/architectures/pyg_architectures.py:154: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert edge_feats.shape[0] == g.num_edges\n",
      "/home/dom/graphium/graphium/nn/architectures/global_architectures.py:1190: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  if torch.prod(torch.as_tensor(e.shape[:-1])) == 0:\n",
      "/home/dom/graphium/graphium/nn/architectures/global_architectures.py:1190: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if torch.prod(torch.as_tensor(e.shape[:-1])) == 0:\n",
      "/home/dom/graphium/graphium/nn/base_graph_layer.py:277: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert edge_index.min() >= 0\n",
      "/home/dom/graphium/graphium/nn/base_graph_layer.py:278: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert edge_index.max() < torch.iinfo(edge_index.dtype).max\n",
      "/home/dom/graphium/graphium/nn/base_graph_layer.py:281: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert edge_index.size(0) == 2\n",
      "/home/dom/graphium/graphium/nn/pyg_layers/gps_pyg.py:144: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  on_ipu = (\"graph_is_true\" in batch.keys) and (not batch.graph_is_true.all())\n",
      "/home/dom/graphium/graphium/nn/pyg_layers/gps_pyg.py:146: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  max_num_nodes_per_graph = batch.dataset_max_nodes_per_graph[0].item()\n",
      "/home/dom/graphium/graphium/ipu/to_dense_batch.py:57: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  batch_size = int(batch.max()) + 1\n",
      "/home/dom/graphium/graphium/ipu/to_dense_batch.py:80: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert (\n",
      "/home/dom/graphium/graphium/ipu/ipu_wrapper.py:20: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if targets[task].shape == preds[task].shape:\n",
      "/home/dom/graphium/graphium/trainer/predictor.py:422: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  total_norm = torch.tensor(0.0)\n",
      "/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/wandb/util.py:604: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return obj.item(), True\n",
      "[17:17:11.240] [poptorch:cpp] [warning] Graph contains an unused input %this_input : Long(1, strides=[1], requires_grad=0, device=cpu)\n",
      "Graph compilation: 100%|██████████| 100/100 [00:02<00:00]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d42decb8e540f789449ccc28c479c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70de2d219c148b3b6e24ebacb2921c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce940eb978d94591938ca2b8e1f3c350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df03a32b5354f87809e8853ef1875ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549753c8e3e7491991a8a9015ecea233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab418d2f84de481689364a5faade7d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>alpha/MSELossIPU/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>alpha/MSELossIPU/val</td><td>▄█▃▄▁</td></tr><tr><td>alpha/loss/val</td><td>▄█▃▄▁</td></tr><tr><td>alpha/mae/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>alpha/mae/val</td><td>▅█▃▄▁</td></tr><tr><td>alpha/mean_pred/train</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>alpha/mean_pred/val</td><td>▄█▂▂▁</td></tr><tr><td>alpha/mean_target/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>alpha/mean_target/val</td><td>▁▁▁▁▁</td></tr><tr><td>alpha/median_pred/train</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>alpha/median_pred/val</td><td>▁█▃▃▁</td></tr><tr><td>alpha/median_target/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>alpha/median_target/val</td><td>▁▁▁▁▁</td></tr><tr><td>alpha/pearsonr/train</td><td>▁█▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>alpha/pearsonr/val</td><td>▁▇▆▇█</td></tr><tr><td>alpha/std_pred/train</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>alpha/std_pred/val</td><td>█▃▂▁▃</td></tr><tr><td>alpha/std_target/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>alpha/std_target/val</td><td>▁▁▁▁▁</td></tr><tr><td>cv/MSELossIPU/train</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>cv/MSELossIPU/val</td><td>▄█▄▃▁</td></tr><tr><td>cv/loss/val</td><td>▄█▄▃▁</td></tr><tr><td>cv/mae/train</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>cv/mae/val</td><td>▅█▄▃▁</td></tr><tr><td>cv/mean_pred/train</td><td>█▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>cv/mean_pred/val</td><td>▁█▅▄▂</td></tr><tr><td>cv/mean_target/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>cv/mean_target/val</td><td>▁▁▁▁▁</td></tr><tr><td>cv/median_pred/train</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>cv/median_pred/val</td><td>▁█▄▃▂</td></tr><tr><td>cv/median_target/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>cv/median_target/val</td><td>▁▁▁▁▁</td></tr><tr><td>cv/pearsonr/train</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>cv/pearsonr/val</td><td>▁▇▆██</td></tr><tr><td>cv/std_pred/train</td><td>█▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>cv/std_pred/val</td><td>█▄▄▁▅</td></tr><tr><td>cv/std_target/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>cv/std_target/val</td><td>▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>grad_norm</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>homo/MSELossIPU/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>homo/MSELossIPU/val</td><td>█▅▁▂▂</td></tr><tr><td>homo/loss/val</td><td>█▅▁▂▂</td></tr><tr><td>homo/mae/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>homo/mae/val</td><td>█▅▁▃▃</td></tr><tr><td>homo/mean_pred/train</td><td>▁▄███████████████████████████████</td></tr><tr><td>homo/mean_pred/val</td><td>▁█▄▄▄</td></tr><tr><td>homo/mean_target/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>homo/mean_target/val</td><td>▁▁▁▁▁</td></tr><tr><td>homo/median_pred/train</td><td>█▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>homo/median_pred/val</td><td>▁▅▄▇█</td></tr><tr><td>homo/median_target/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>homo/median_target/val</td><td>▁▁▁▁▁</td></tr><tr><td>homo/pearsonr/train</td><td>█▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>homo/pearsonr/val</td><td>███▅▁</td></tr><tr><td>homo/std_pred/train</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>homo/std_pred/val</td><td>█▃▂▁▂</td></tr><tr><td>homo/std_target/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>homo/std_target/val</td><td>▁▁▁▁▁</td></tr><tr><td>loss</td><td>▁▁▁</td></tr><tr><td>loss/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss/val</td><td>▅█▃▃▁</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>alpha/MSELossIPU/train</td><td>10.27925</td></tr><tr><td>alpha/MSELossIPU/val</td><td>0.90438</td></tr><tr><td>alpha/loss/val</td><td>0.90438</td></tr><tr><td>alpha/mae/train</td><td>1.92692</td></tr><tr><td>alpha/mae/val</td><td>0.5743</td></tr><tr><td>alpha/mean_pred/train</td><td>-0.0</td></tr><tr><td>alpha/mean_pred/val</td><td>0.05032</td></tr><tr><td>alpha/mean_target/train</td><td>-1.47591</td></tr><tr><td>alpha/mean_target/val</td><td>-0.05393</td></tr><tr><td>alpha/median_pred/train</td><td>-0.0</td></tr><tr><td>alpha/median_pred/val</td><td>0.09372</td></tr><tr><td>alpha/median_target/train</td><td>-0.81494</td></tr><tr><td>alpha/median_target/val</td><td>-0.04535</td></tr><tr><td>alpha/pearsonr/train</td><td>0.24189</td></tr><tr><td>alpha/pearsonr/val</td><td>0.70787</td></tr><tr><td>alpha/std_pred/train</td><td>0.0</td></tr><tr><td>alpha/std_pred/val</td><td>0.63476</td></tr><tr><td>alpha/std_target/train</td><td>3.11787</td></tr><tr><td>alpha/std_target/val</td><td>1.28429</td></tr><tr><td>cv/MSELossIPU/train</td><td>7.34846</td></tr><tr><td>cv/MSELossIPU/val</td><td>0.71549</td></tr><tr><td>cv/loss/val</td><td>0.71549</td></tr><tr><td>cv/mae/train</td><td>1.7832</td></tr><tr><td>cv/mae/val</td><td>0.59933</td></tr><tr><td>cv/mean_pred/train</td><td>-0.0</td></tr><tr><td>cv/mean_pred/val</td><td>0.02737</td></tr><tr><td>cv/mean_target/train</td><td>-1.33105</td></tr><tr><td>cv/mean_target/val</td><td>-0.08344</td></tr><tr><td>cv/median_pred/train</td><td>-0.0</td></tr><tr><td>cv/median_pred/val</td><td>0.08583</td></tr><tr><td>cv/median_target/train</td><td>-0.73486</td></tr><tr><td>cv/median_target/val</td><td>-0.0361</td></tr><tr><td>cv/pearsonr/train</td><td>-0.84246</td></tr><tr><td>cv/pearsonr/val</td><td>0.61503</td></tr><tr><td>cv/std_pred/train</td><td>0.0</td></tr><tr><td>cv/std_pred/val</td><td>0.60702</td></tr><tr><td>cv/std_target/train</td><td>2.58691</td></tr><tr><td>cv/std_target/val</td><td>1.06456</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>grad_norm</td><td>0.0</td></tr><tr><td>homo/MSELossIPU/train</td><td>3.00724</td></tr><tr><td>homo/MSELossIPU/val</td><td>1.10813</td></tr><tr><td>homo/loss/val</td><td>1.10813</td></tr><tr><td>homo/mae/train</td><td>0.92035</td></tr><tr><td>homo/mae/val</td><td>0.81845</td></tr><tr><td>homo/mean_pred/train</td><td>0.0</td></tr><tr><td>homo/mean_pred/val</td><td>0.02063</td></tr><tr><td>homo/mean_target/train</td><td>-0.43686</td></tr><tr><td>homo/mean_target/val</td><td>-0.0837</td></tr><tr><td>homo/median_pred/train</td><td>0.0</td></tr><tr><td>homo/median_pred/val</td><td>0.00169</td></tr><tr><td>homo/median_target/train</td><td>0.04636</td></tr><tr><td>homo/median_target/val</td><td>-0.10706</td></tr><tr><td>homo/pearsonr/train</td><td>0.01569</td></tr><tr><td>homo/pearsonr/val</td><td>0.11083</td></tr><tr><td>homo/std_pred/train</td><td>0.0</td></tr><tr><td>homo/std_pred/val</td><td>0.2037</td></tr><tr><td>homo/std_target/train</td><td>1.75284</td></tr><tr><td>homo/std_target/val</td><td>1.05716</td></tr><tr><td>loss</td><td>6.87832</td></tr><tr><td>loss/train</td><td>6.87832</td></tr><tr><td>loss/val</td><td>0.90933</td></tr><tr><td>train/grad_norm</td><td>0.0</td></tr><tr><td>trainer/global_step</td><td>29</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">tutorial-run</strong>: <a href=\"https://wandb.ai/multitask-gnn/multitask-gnn/runs/1ss172i9\" target=\"_blank\">https://wandb.ai/multitask-gnn/multitask-gnn/runs/1ss172i9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220920_171648-1ss172i9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the model training\n",
    "with SafeRun(name=\"TRAINING\", raise_error=cfg[\"constants\"][\"raise_train_error\"], verbose=True):\n",
    "    trainer.fit(model=predictor, datamodule=datamodule)\n",
    "\n",
    "# Exit WandB\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "Once the model is trained, we can use the same datamodule to get the results on the test set. Here, `ckpt_path` refers to the checkpoint path where the model at the best validation step was saved. Thus, the results on the test set represent the early stopping.\n",
    "\n",
    "All the metrics that were computed on the validation set are then computed on the test set, printed, and saved into the `metrics.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:154: LightningDeprecationWarning: The `LightningModule.get_progress_bar_dict` method was deprecated in v1.5 and will be removed in v1.7. Please use the `ProgressBarBase.get_metrics` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4625fffadb44c49db13da8a06e5e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mols to ids:   0%|          | 0/603 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/dom/graphium/models_checkpoints/QM9/tutorial_model.ckpt\n",
      "Loaded model weights from checkpoint at /home/dom/graphium/models_checkpoints/QM9/tutorial_model.ckpt\n",
      "2022-09-20 17:18:37.268 | INFO     | graphium.ipu.ipu_dataloader:create_ipu_dataloader:230 - Estimating pack max_pack_size=54 or max_pack_size_per_graph=9.0\n",
      "2022-09-20 17:18:37.268 | INFO     | graphium.ipu.ipu_dataloader:create_ipu_dataloader:233 - Provided `max_num_nodes=72`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "MultitaskDataset\n",
      "\tabout = test set\n",
      "\tnum_graphs_total = 201\n",
      "\tnum_nodes_total = 1751\n",
      "\tmax_num_nodes_per_graph = 9\n",
      "\tmin_num_nodes_per_graph = 1\n",
      "\tstd_num_nodes_per_graph = 0.9443829267824616\n",
      "\tmean_num_nodes_per_graph = 8.711442786069652\n",
      "\tnum_edges_total = 3748\n",
      "\tmax_num_edges_per_graph = 26\n",
      "\tmin_num_edges_per_graph = 0\n",
      "\tstd_num_edges_per_graph = 3.0647412282392468\n",
      "\tmean_num_edges_per_graph = 18.64676616915423\n",
      "-------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4fae924ae341bca549748250829f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:18:40.730] [poptorch:cpp] [warning] Graph contains an unused input %this_input : Long(1, strides=[1], requires_grad=0, device=cpu)\n",
      "Graph compilation: 100%|██████████| 100/100 [00:01<00:00]\n",
      "Exception in thread SockSrvRdThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 113, in run\n",
      "    shandler(sreq)\n",
      "  File \"/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/wandb/sdk/service/server_sock.py\", line 172, in server_record_publish\n",
      "    iface = self._mux.get_stream(stream_id).interface\n",
      "  File \"/home/dom/.venv/graphium_ipu/lib/python3.8/site-packages/wandb/sdk/service/streams.py\", line 186, in get_stream\n",
      "    stream = self._streams[stream_id]\n",
      "KeyError: '1ss172i9'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  alpha/MSELossIPU/test     1.0208719968795776\n",
      "     alpha/loss/test        1.0208719968795776\n",
      "     alpha/mae/test         0.5369145274162292\n",
      "  alpha/mean_pred/test     -0.043575093150138855\n",
      " alpha/mean_target/test     -0.1731886863708496\n",
      " alpha/median_pred/test    0.020035069435834885\n",
      "alpha/median_target/test     -0.05999755859375\n",
      "   alpha/pearsonr/test      0.6431294679641724\n",
      "   alpha/std_pred/test      0.6613938808441162\n",
      "  alpha/std_target/test     1.2930139303207397\n",
      "   cv/MSELossIPU/test       0.7984611392021179\n",
      "      cv/loss/test          0.7984611392021179\n",
      "       cv/mae/test          0.5717160701751709\n",
      "    cv/mean_pred/test      -0.06430188566446304\n",
      "   cv/mean_target/test     -0.08974086493253708\n",
      "   cv/median_pred/test     0.014351803809404373\n",
      "  cv/median_target/test      -0.06439208984375\n",
      "    cv/pearsonr/test         0.663591742515564\n",
      "    cv/std_pred/test         0.63597571849823\n",
      "   cv/std_target/test        1.180733561515808\n",
      "  homo/MSELossIPU/test       1.14460027217865\n",
      "     homo/loss/test          1.14460027217865\n",
      "      homo/mae/test         0.7968456149101257\n",
      "   homo/mean_pred/test     0.004068718757480383\n",
      "  homo/mean_target/test     0.1092241033911705\n",
      "  homo/median_pred/test    0.0017465166747570038\n",
      " homo/median_target/test      0.1390380859375\n",
      "   homo/pearsonr/test       0.1387491226196289\n",
      "   homo/std_pred/test       0.2090565264225006\n",
      "  homo/std_target/test       1.07249116897583\n",
      "        loss/test           0.9879778027534485\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'homo/mean_pred/test': 0.004068718757480383,\n",
       "  'homo/std_pred/test': 0.2090565264225006,\n",
       "  'homo/median_pred/test': 0.0017465166747570038,\n",
       "  'homo/mean_target/test': 0.1092241033911705,\n",
       "  'homo/std_target/test': 1.07249116897583,\n",
       "  'homo/median_target/test': 0.1390380859375,\n",
       "  'homo/mae/test': 0.7968456149101257,\n",
       "  'homo/pearsonr/test': 0.1387491226196289,\n",
       "  'homo/MSELossIPU/test': 1.14460027217865,\n",
       "  'homo/loss/test': 1.14460027217865,\n",
       "  'alpha/mean_pred/test': -0.043575093150138855,\n",
       "  'alpha/std_pred/test': 0.6613938808441162,\n",
       "  'alpha/median_pred/test': 0.020035069435834885,\n",
       "  'alpha/mean_target/test': -0.1731886863708496,\n",
       "  'alpha/std_target/test': 1.2930139303207397,\n",
       "  'alpha/median_target/test': -0.05999755859375,\n",
       "  'alpha/mae/test': 0.5369145274162292,\n",
       "  'alpha/pearsonr/test': 0.6431294679641724,\n",
       "  'alpha/MSELossIPU/test': 1.0208719968795776,\n",
       "  'alpha/loss/test': 1.0208719968795776,\n",
       "  'cv/mean_pred/test': -0.06430188566446304,\n",
       "  'cv/std_pred/test': 0.63597571849823,\n",
       "  'cv/median_pred/test': 0.014351803809404373,\n",
       "  'cv/mean_target/test': -0.08974086493253708,\n",
       "  'cv/std_target/test': 1.180733561515808,\n",
       "  'cv/median_target/test': -0.06439208984375,\n",
       "  'cv/mae/test': 0.5717160701751709,\n",
       "  'cv/pearsonr/test': 0.663591742515564,\n",
       "  'cv/MSELossIPU/test': 0.7984611392021179,\n",
       "  'cv/loss/test': 0.7984611392021179,\n",
       "  'loss/test': 0.9879778027534485}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = trainer.checkpoint_callbacks[0].best_model_path\n",
    "predictor.set_max_nodes_edges_per_graph(datamodule, stages=['test'])\n",
    "trainer.test(model=predictor, datamodule=datamodule, ckpt_path=ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc02f5cdc78e740d0e3d50b3e0a92193dd610f8dfa26c6f9f34c1bd27276294a"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
