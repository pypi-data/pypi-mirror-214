{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eedd2609-33b1-4f1e-91ce-76d58874d13a",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2454c459-8408-4027-81c3-6e567696d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import itertools as it\n",
    "\n",
    "# Optional libraries for dev purposes\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import dump, load\n",
    "import time\n",
    "# Python implementation of Matlab's imresize due to differing results\n",
    "# Original code found here: https://github.com/fatheral/matlab_imresize\n",
    "# Note this code was last updated Aug. 2021\n",
    "USER=\"ataha\" # Update this to or path below to where imresize.py is located\n",
    "sys.path.append(f'/home/ROBARTS/ataha/Desktop/auto-afids/autofid_main/training/')\n",
    "from imresize import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a7e7a7-f5d5-4e81-acfb-b8d33f101573",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e54a7de-8b72-4559-9426-18b60838b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nii_metadata(nii_path):\n",
    "    \"\"\"Load in nifti data and header information and normalize MRI volume\"\"\"\n",
    "    nii = nib.load(nii_path)\n",
    "    nii_affine = nii.affine\n",
    "    nii_data = nii.get_fdata()\n",
    "    #normalization \n",
    "    nii_data = (nii_data - nii_data.min())/ (nii_data.max() - nii_data.min())\n",
    "    return nii_affine, nii_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a380263-7adc-44b3-bdd2-e3edfd155c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fid(fcsv_path, fid_num):\n",
    "    \"\"\"Extract specific fiducial's spatial coordinates\"\"\"\n",
    "    fcsv_df = pd.read_csv(fcsv_path, sep=\",\", header=2)\n",
    "\n",
    "    return fcsv_df.loc[fid_num, [\"x\", \"y\", \"z\"]].to_numpy(dtype=\"single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e6e509-a5c7-455c-bd07-15ac1ee8cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_voxel2world(fid_voxel, nii_affine, resample_size=1, padding=None):\n",
    "    \"\"\"Transform fiducials in voxel coordinates to world coordinates\n",
    "\n",
    "    Optionally, resample to match resampled image\n",
    "    \"\"\"\n",
    "\n",
    "    # Translation\n",
    "    fid_world = fid_voxel.T + nii_affine[:3, 3:4]\n",
    "    # Rotation\n",
    "    fid_world = np.dot(fid_voxel, nii_affine[:3, :3])\n",
    "\n",
    "    if padding:\n",
    "        fid_voxel = np.pad(fid_voxel, padding, mode=\"constant\")\n",
    "\n",
    "    return fid_world.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c0660aa-6241-4a4d-9a4d-8b220cf11abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(img, size):\n",
    "    \"\"\"Resize image using Matlab's imresize\"\"\"\n",
    "    return imresize(img, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7958f6a1-7e63-4f08-b1f6-d220cfb3c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integral_volume(resampled_image):\n",
    "    '''Compute zero-padded resampled volume'''\n",
    "    iv_image = resampled_image.cumsum(0).cumsum(1).cumsum(2)\n",
    "    iv_zeropad = np.zeros((iv_image.shape[0]+1, iv_image.shape[1]+1, iv_image.shape[2]+1))\n",
    "    iv_zeropad[1:, 1:, 1:] = iv_image\n",
    "    \n",
    "    return iv_zeropad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608edd33-2b7d-46be-b1e6-c6c2efb817f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_world2voxel(fid_world, nii_affine, resample_size=1, padding=None):\n",
    "    \"\"\"Transform fiducials in world coordinates to voxel coordinates\n",
    "\n",
    "    Optionally, resample to match resampled image\n",
    "    \"\"\"\n",
    "\n",
    "    # Translation\n",
    "    fid_voxel = fid_world.T - nii_affine[:3, 3:4]\n",
    "    # Rotation\n",
    "    fid_voxel = np.dot(fid_voxel, np.linalg.inv(nii_affine[:3, :3]))\n",
    "\n",
    "    # Round to nearest voxel\n",
    "    fid_voxel = np.rint(np.diag(fid_voxel) * resample_size)\n",
    "\n",
    "    if padding:\n",
    "        fid_voxel = np.pad(fid_voxel, padding, mode=\"constant\")\n",
    "\n",
    "    return fid_voxel.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cedc00e-1bde-43c0-812d-bc0687623687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write results into fcsv file \n",
    "def seg_to_fcsv(weighted_centroids, fcsv_template, fcsv_output):\n",
    "    # Read in fcsv template\n",
    "    with open(fcsv_template, \"r\") as f:\n",
    "        fcsv = [line.strip() for line in f]\n",
    "\n",
    "    # Loop over fiducials\n",
    "    for fid in range(1, 33):\n",
    "        # Update fcsv, skipping header\n",
    "        line_idx = fid + 2\n",
    "        centroid_idx = fid - 1\n",
    "        fcsv[line_idx] = fcsv[line_idx].replace(\n",
    "            f\"afid{fid}_x\", str(weighted_centroids[centroid_idx][0])\n",
    "        )\n",
    "        fcsv[line_idx] = fcsv[line_idx].replace(\n",
    "            f\"afid{fid}_y\", str(weighted_centroids[centroid_idx][1])\n",
    "        )\n",
    "        fcsv[line_idx] = fcsv[line_idx].replace(\n",
    "            f\"afid{fid}_z\", str(weighted_centroids[centroid_idx][2])\n",
    "        )\n",
    "\n",
    "    # Write output fcsv\n",
    "    with open(fcsv_output, \"w\") as f:\n",
    "        f.write(\"\\n\".join(line for line in fcsv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a290ed0-3c14-41f1-bb25-5af02f6915c5",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a48cfc-30f6-441b-863c-52664edd4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_space = 10\n",
    "PAD_FLAG = False\n",
    "PADDING = 0\n",
    "#describes haar like feature coordiantes \n",
    "feature_offsets = f\"/home/ROBARTS/{USER}/Desktop/auto-afids/autofid_main/training/feature_offsets.npz\"\n",
    "SIZE = 1  # Fixed for now but make variable\n",
    "\n",
    "# Directories\n",
    "DATASET = 'HCP'\n",
    "BASE_DIR = f\"/home/ROBARTS/{USER}/graham/projects/ctb-akhanf/cfmm-bids/Khan/clinical_imaging/autoafids\"\n",
    "T1W_DIR = f\"{BASE_DIR}/data/{DATASET}/derivatives/afids_mni\"\n",
    "SUBJECT_IDS = [\n",
    "    subject for subject in os.listdir(T1W_DIR) if \"sub-\" in subject]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72d9d0a4-ae9d-4699-8d0f-e50fd28ddbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting on subject sub-130013\n",
      "predicting AFID#30\n",
      "29.428035988539538\n",
      "voxel coordinates with most liklihood of being AFID #30 are: [93 69 73]\n",
      "coordinates in world are: [ -3. -63.  -5.]\n",
      "predicting AFID#30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(all_samples\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     56\u001b[0m     min_corner_list[idx\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4000\u001b[39m : (idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4000\u001b[39m] \u001b[38;5;241m=\u001b[39m all_samples[idx] \u001b[38;5;241m+\u001b[39m smin\n\u001b[0;32m---> 57\u001b[0m     max_corner_list[idx\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4000\u001b[39m : (idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4000\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mall_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msmax\u001b[49m\n\u001b[1;32m     59\u001b[0m corner_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((min_corner_list, max_corner_list))\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m#compute the integral image for more efficient generation of haar-like features\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for sub in range(0,31): \n",
    "    SUBJECT = SUBJECT_IDS[sub]\n",
    "    print(f'predicting on subject {SUBJECT}')\n",
    "    arrays_of_afids = np.empty((3,), dtype=float)\n",
    "    for i in range (1,33):\n",
    "        FID_NUM = 30\n",
    "        #MNI stuff \n",
    "        nii_path_mni = f\"{T1W_DIR}/{SUBJECT}/{SUBJECT}_space-MNI152NLin2009cAsym_T1w.nii.gz\"\n",
    "        mni_aff, mni_img = read_nii_metadata(nii_path_mni)\n",
    "        fcsv_path_mni = f\"/home/ROBARTS/ataha/Desktop/autoafids/{SUBJECT}15.fcsv\"\n",
    "        print(f'predicting AFID#{FID_NUM}')\n",
    "        #getting \"consensus\" coordinates of AFID in MNI to enable more efficinet training and less exhaustive search \n",
    "        fid_world_mni = get_fid(fcsv_path_mni, FID_NUM - 1)\n",
    "        resampled_fid_mni = fid_world2voxel(fid_world_mni, mni_aff, resample_size=SIZE, padding=PADDING)\n",
    "\n",
    "        # Load image -- assumes correct bids spec \n",
    "        nii_path = f\"{T1W_DIR}/{SUBJECT}/{SUBJECT}_space-MNI152NLin2009cAsym_T1w.nii.gz\"\n",
    "        aff, img = read_nii_metadata(nii_path)\n",
    "        # Resampled image\n",
    "        resampled_image = image_resize(img, SIZE)\n",
    "        # Optionally pad image\n",
    "        if PADDING:\n",
    "            resampled_image = np.pad(resampled_image, PADDING, mode=\"constant\")\n",
    "\n",
    "        # Get image samples intialized using MNI\n",
    "        inner_its = [\n",
    "            range(resampled_fid_mni[0] - sampling_space, resampled_fid_mni[0] + sampling_space+1),\n",
    "            range(resampled_fid_mni[1] - sampling_space, resampled_fid_mni[1] + sampling_space+1),\n",
    "            range(resampled_fid_mni[2] - sampling_space, resampled_fid_mni[2] + sampling_space+1),\n",
    "        ]\n",
    "        inner_samples = [t for t in it.product(*inner_its)]\n",
    "\n",
    "        outer_its = [\n",
    "            range(resampled_fid_mni[0] - sampling_space*2, resampled_fid_mni[0] + sampling_space*2+1, 2),\n",
    "            range(resampled_fid_mni[1] - sampling_space*2, resampled_fid_mni[1] + sampling_space*2+1, 2),\n",
    "            range(resampled_fid_mni[2] - sampling_space*2, resampled_fid_mni[2] + sampling_space*2+1, 2),\n",
    "        ]\n",
    "        outer_samples = [t for t in it.product(*outer_its)]\n",
    "\n",
    "        # Concatenate and retain unique samples and\n",
    "        all_samples = np.unique(\n",
    "            np.array(inner_samples + outer_samples), axis=0)\n",
    "\n",
    "        # Compute Haar-like features features\n",
    "        # Make this optional to load or create\n",
    "        feature_offsets_data = np.load(feature_offsets)\n",
    "        smin, smax = feature_offsets_data[\"arr_0\"], feature_offsets_data[\"arr_1\"]\n",
    "\n",
    "        # Generate bounding cube surrounding features\n",
    "        min_corner_list = np.zeros((4000 * all_samples.shape[0], 3)).astype('uint8')\n",
    "        max_corner_list = np.zeros((4000 * all_samples.shape[0], 3)).astype('uint8')\n",
    "\n",
    "        for idx in range(all_samples.shape[0]):\n",
    "            min_corner_list[idx*4000 : (idx+1)*4000] = all_samples[idx] + smin\n",
    "            max_corner_list[idx*4000 : (idx+1)*4000] = all_samples[idx] + smax\n",
    "\n",
    "        corner_list = np.hstack((min_corner_list, max_corner_list))\n",
    "\n",
    "        #compute the integral image for more efficient generation of haar-like features\n",
    "        iv_image = integral_volume(resampled_image)\n",
    "\n",
    "        #intialize a numpy array to store features\n",
    "        testerarr = np.zeros((4000 * all_samples.shape[0])) \n",
    "\n",
    "        # Generate features using integral volume\n",
    "        numerator = (\n",
    "            iv_image[corner_list[:, 3] + 1, corner_list[:, 4] + 1, corner_list[:, 5] + 1]\n",
    "            - iv_image[corner_list[:, 0], corner_list[:, 4] + 1, corner_list[:, 5] + 1]\n",
    "            - iv_image[corner_list[:, 3] + 1, corner_list[:, 4] + 1, corner_list[:, 2]]\n",
    "            - iv_image[corner_list[:, 3] + 1, corner_list[:, 1], corner_list[:, 5] + 1]\n",
    "            + iv_image[corner_list[:, 3] + 1, corner_list[:, 1], corner_list[:, 2]]\n",
    "            + iv_image[corner_list[:, 0], corner_list[:, 1], corner_list[:, 5] + 1]\n",
    "            + iv_image[corner_list[:, 0], corner_list[:, 4] + 1, corner_list[:, 2]]\n",
    "            - iv_image[corner_list[:, 0], corner_list[:, 1], corner_list[:, 2]]\n",
    "        )\n",
    "\n",
    "        denomerator = (\n",
    "            (corner_list[:, 3]-corner_list[:, 0]+1)\n",
    "            *(corner_list[:, 4]-corner_list[:, 1]+1)\n",
    "            *(corner_list[:, 5]-corner_list[:, 2]+1)\n",
    "        )\n",
    "\n",
    "        #dump features into intialized variable\n",
    "        testerarr = numerator/denomerator\n",
    "        vector1arr = np.zeros((4000 * all_samples.shape[0]))\n",
    "        vector2arr = np.zeros((4000 * all_samples.shape[0]))\n",
    "\n",
    "        for index in range(all_samples.shape[0]):\n",
    "            vector = range(index * 4000, index * 4000 + 2000)\n",
    "            vector1arr[index * 4000 : (index + 1) * 4000 - 2000] = vector\n",
    "\n",
    "        for index in range(all_samples.shape[0]):\n",
    "            vector = range(index * 4000 + 2000, index * 4000 + 4000)\n",
    "            vector2arr[index * 4000 + 2000 : (index + 1) * 4000] = vector\n",
    "\n",
    "        vector1arr[0] = 1\n",
    "        vector1arr = vector1arr[vector1arr != 0]\n",
    "        vector1arr[0] = 0\n",
    "        vector2arr = vector2arr[vector2arr != 0]\n",
    "        vector1arr = vector1arr.astype(int)\n",
    "        vector2arr = vector2arr.astype(int)\n",
    "\n",
    "        diff = testerarr[vector1arr] - testerarr[vector2arr]\n",
    "        diff = np.reshape(diff, (all_samples.shape[0], 2000))\n",
    "\n",
    "\n",
    "        #model prediction \n",
    "        clf = load(f'{FID_NUM}_{sampling_space}x{sampling_space}x{sampling_space}.joblib') \n",
    "        answer = clf.predict(diff)\n",
    "\n",
    "        #extracting the smallest eucleidean distance from predictions \n",
    "        df = pd.DataFrame(answer)\n",
    "        print(df[0].max())\n",
    "        idx = df[0].idxmax()\n",
    "\n",
    "        #reverse look-up to find voxel lowest distance coressponds to! \n",
    "        print(f'voxel coordinates with most liklihood of being AFID #{FID_NUM} are: {all_samples[idx]}')\n",
    "\n",
    "        AFID = aff[:3, :3].dot(all_samples[idx]) + aff[:3, 3]\n",
    "        print(f'coordinates in world are: {AFID}')\n",
    "\n",
    "        arrays_of_afids = np.vstack((arrays_of_afids, AFID))\n",
    "\n",
    "    seg_to_fcsv(arrays_of_afids[1:].astype(int), '/home/ROBARTS/ataha/Desktop/afids-auto/afids-auto-apply/resources/afids_template.fcsv', f'/home/ROBARTS/ataha/Desktop/autoafids/new_nativetrained/{SUBJECT}_{sampling_rate}.fcsv')\n",
    "\n",
    "end = time.time()\n",
    "print(f'time taken to predict all afids for all subject {end - start}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
