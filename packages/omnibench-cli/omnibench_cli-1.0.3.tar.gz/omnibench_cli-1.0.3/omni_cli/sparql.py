import datetime
from string import Template

import humanize
import rdflib
from tabulate import tabulate

from SPARQLWrapper import SPARQLWrapper, JSON

from .config import get_annotation_endpoint_query
from .config import get_graph_endpoint_query
from .model import OrchestratorRun
from .plot import plot_connected_component, plot_graph


genListQuery = """
PREFIX prov: <http://www.w3.org/ns/prov#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
SELECT ?act ?gen ?start ?end WHERE {
  SERVICE <$graph> {
      ?gen a prov:Generation .
      ?gen prov:activity ?act . 
      ?act prov:startedAtTime ?start.
      ?act prov:endedAtTime ?end;
  }
}
ORDER BY DESC(?start)
LIMIT 100
"""

# TODO: filter by namespace

lastGenQuery = """
PREFIX prov: <http://www.w3.org/ns/prov#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
SELECT ?act ?gen ?start ?end WHERE {
  SERVICE <$graph> {
      ?gen a prov:Generation .
      ?gen prov:activity ?act . 
      ?act prov:startedAtTime ?start.
      ?act prov:endedAtTime ?end;
  }
}
ORDER BY DESC(?start)
LIMIT 1
"""

epochForOrchestratorQuery = """
PREFIX prov: <http://www.w3.org/ns/prov#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX omni: <http://omnibenchmark.org/ns#>

SELECT ?run ?epoch ?start ?end WHERE {
  SERVICE <$annotations> {
      ?run omni:hasName "$name" .
      ?run omni:hasEpoch ?epoch.
      ?run prov:startedAtTime ?start.
      OPTIONAL {?run prov:endedAtTime ?end.}
  }
} 
ORDER BY DESC(?start)
LIMIT 10
"""

lastEpochForOrchestratorQuery = """
PREFIX prov: <http://www.w3.org/ns/prov#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX omni: <http://omnibenchmark.org/ns#>

SELECT ?run ?epoch ?start ?end WHERE {
  SERVICE <$annotations> {
      ?run omni:hasName "$name" .
      ?run omni:hasEpoch ?epoch.
      ?run prov:startedAtTime ?start.
      OPTIONAL {?run prov:endedAtTime ?end.}
  }
} 
ORDER BY DESC(?start)
LIMIT 1
"""

lastActivityForProject = """
PREFIX schema: <http://schema.org/>
PREFIX prov: <http://www.w3.org/ns/prov#>

SELECT ?act WHERE {
  ?plan schema:name "$project".
  ?assoc prov:hadPlan ?plan.
  ?act prov:qualifiedAssociation ?assoc.
  ?act prov:endedAtTime ?end.
}
ORDER BY DESC(?end)
LIMIT 1
"""

# TODO - this query is not accurate!
# See filesForEpochRun - once we go to the dataset, the modifiedDate does not
# apply to the location itself, but to the broader dataset.
filesForGenerationQuery = """
PREFIX schema: <http://schema.org/>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX prov: <http://www.w3.org/ns/prov#>
PREFIX renku: <https://swissdatasciencecenter.github.io/renku-ontology#>
SELECT DISTINCT ?part ?source ?checksum ?modified ?keywords WHERE {
  FILTER (?gen = <$generation>)
        ?dataset schema:hasPart ?files .
        ?dataset schema:dateModified ?modified .
        ?dataset schema:keywords ?keywords .
        ?files prov:entity ?datasetEntity .
        ?datasetEntity prov:qualifiedGeneration ?gen .
        ?dataset schema:hasPart ?part .
        ?part prov:entity ?entity .
        ?part renku:source ?source .
        ?entity renku:checksum ?checksum .
}
"""


# This FEDERATED query is optimized to avoid run-offs: it gets
# location for all the files recorded to have been generated by renku outputs
# as part of all the runs for a given epoch (the last epoch, by default).
filesForEpochRun = """
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX omni: <http://omnibenchmark.org/ns#>
PREFIX prov: <http://www.w3.org/ns/prov#>
PREFIX renku: <https://swissdatasciencecenter.github.io/renku-ontology#>
PREFIX schema: <http://schema.org/>

SELECT DISTINCT ?location ?checksum ?keywords ?ended WHERE {
  # annotations query: select all generations for all the runs belonging
  # to the last epoch
  SERVICE <$annotations> {
    {
      SELECT ?run WHERE {
        ?run omni:hasName "$project" .
        ?run omni:hasEpoch ?epoch .
        ?run prov:startedAtTime ?start .
      }
      ORDER BY DESC(?start)
      LIMIT 1
   }
   {
      SELECT ?act WHERE {
        ?act prov:wasStartedBy ?run .
      }
    }
  }
  
  # knowledge graph query: select files for the generation associated to 
  # the activities returned above
  SERVICE <$graph> {
    # get the ending time to sort the entities chronologically
    ?act prov:endedAtTime ?ended .
    ?gen prov:activity ?act .
    ?entity prov:qualifiedGeneration ?gen .
    # what is the (relative) location of the entity?
    ?entity prov:atLocation ?location .
    # get md5 checksum of the file obtained by dereferencing the entity
    ?entity renku:checksum ?checksum .
    # we ascend to the dataset-files entity just to retrieve the keywords
    ?files prov:entity ?entity .
    ?dataset schema:hasPart ?files .
    ?dataset schema:keywords ?keywords .
  }
}
ORDER BY ASC(?ended)
"""

# Construct the DAG for input/output files in a Plan, for all the activities
# coming from the last epoch for a given benchmark.
# This query is parametrized for three variables:
#
# $annotations: the annotations SPARQL endpoint
# $graph: the main knowledge graph SPARQL endpoint
# $benchmark: the benchmark name
provenanceForLastEpoch = """
PREFIX schema: <http://schema.org/>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX prov: <http://www.w3.org/ns/prov#>
PREFIX renku: <https://swissdatasciencecenter.github.io/renku-ontology#>
PREFIX omni: <http://omnibenchmark.org/ns#>

SELECT DISTINCT ?act ?kw ?ended ?inputfile ?outputfile WHERE {
  # annotations query: select all the activites for the last generation
  # TODO: parametrize by generation too (use filter)
  SERVICE <$annotations> {
    {
      SELECT ?run WHERE {
        ?run omni:hasName "$benchmark" .
        ?run omni:hasEpoch ?epoch .
        ?run prov:startedAtTime ?start .
      }
      ORDER BY DESC(?start)
      LIMIT 1
   }
   {
      SELECT ?act WHERE {
        ?act prov:wasStartedBy ?run .
      }
    }
  }

  SERVICE <$graph> {
      # get the generation for the activity, and descend into
      # the keywords to identify the project that generated it
      ?gen prov:activity ?act .
      ?entity prov:qualifiedGeneration ?gen .
      ?files prov:entity ?entity .
      ?dataset schema:hasPart ?files .
      ?dataset schema:keywords ?kw .

      ?act a prov:Activity .
      ?act prov:qualifiedAssociation ?asoc.
      ?asoc prov:hadPlan ?plan .
      ?plan renku:hasInputs ?input .
      ?input schema:defaultValue ?inputfile .

      # handy heuristic: we do not care about src/*
      FILTER (strstarts(str(?inputfile), 'data/')) .

      ?plan renku:hasOutputs ?output .
      ?output schema:defaultValue ?outputfile .
      # get the ending time to sort the entities chronologically
      ?act prov:endedAtTime ?ended .
  }
}
ORDER BY ASC(?ended)
"""

def fmt_date(ts):
    return ts.strftime("%a, %d %b %Y at %H:%M:%S")

def doQuery(query):
    return rdflib.Graph().query(query)

def queryFromTemplate(template, ctx, endpoint):
    sparql = SPARQLWrapper(endpoint)
    sparql.setReturnFormat(JSON)
    q = Template(template)
    query = q.substitute(**ctx)
    sparql.setQuery(query)
    try:
        result = sparql.queryAndConvert()
        return result
    except Exception as e:
        print("error:", e)

def query_generations():
    ctx = {'graph': get_graph_endpoint_query()}

    q = Template(genListQuery)
    query = q.substitute(**ctx)
    result = doQuery(query)

    table = []
    for row in result:
        _delta = humanize.naturaldelta(row.end.value - row.start.value)
        table.append((fmt_date(row.start.value), _delta, row.gen.split('/')[-1], row.gen.split('/')[-3]))
    print(tabulate(
        table,
        showindex=True,
        headers=["Start", "Duration", "Generation ID", "Activity ID"]))

# TODO: pass generation hash (activity/generation)
# TODO: pass keywords to limit the query

parse_time_with_ms = lambda s: datetime.datetime.strptime(s, "%Y-%m-%dT%H:%M:%S.%f")
parse_time_with_tz = lambda s: datetime.datetime.strptime(s, "%Y-%m-%dT%H:%M:%S%z")
parse_time = lambda s: datetime.datetime.strptime(s, "%Y-%m-%dT%H:%M:%S")

# TODO: we could derive the last-gen as a nested query, instead
# of issuing two different queries.
def query_last_generation():
    ctx = {'graph': get_graph_endpoint_query()}
    q = Template(lastGenQuery)
    query = q.substitute(**ctx)
    r = doQuery(query)
    generation = tuple(r)[0].gen

    ctx = {'generation': generation}
    result = queryFromTemplate(filesForGenerationQuery, ctx)

    data = []

    for r in result["results"]["bindings"]:
        date_str = maybe(r, 'modified')
        data.append({
            'file': maybe(r, 'source'),
            'last_modified': fmt_date(parse_time_with_tz(date_str)),
            'md5sum': maybe(r, 'checksum')[:8],
            'keywords': maybe(r, 'keywords'),
        })

    print(tabulate(
        data, showindex=True,
        headers={"file": "file", "last_modified": "modified", "md5sum": "md5", "keywords": "keywords"}))


def query_epochs_by_name(name):
    endpoint = get_annotation_endpoint_query()
    ctx = {'name': name, 'annotations': endpoint}

    result = queryFromTemplate(
            epochForOrchestratorQuery,
            ctx,
            endpoint=endpoint)

    if result is None:
        print("empty result")
        return

    data = []
    results = result.get('results')
    for r in results["bindings"]:
        started = maybe(r, 'start')
        if started is not None:
            started = fmt_date(parse_time_with_ms(started))
        ended = maybe(r, 'end')
        if ended is not None:
            ended = fmt_date(parse_time_with_ms(ended))
        data.append({
            'name': name,
            'epoch': maybe(r, 'epoch'),
            'started': started,
            'ended': ended,
            'run': maybe(r, 'run')
        })

    print(tabulate(
        data, showindex=True,
        headers={"name": "name", "epoch": "epoch", "started": "started", "ended": "ended", "run": "run"}))

def get_last_run_by_name(name):
    endpoint = get_annotation_endpoint_query()
    ctx = {'name': name, 'annotations': endpoint}
    result = queryFromTemplate(
            lastEpochForOrchestratorQuery,
            ctx,
            endpoint=endpoint)
    if result is None:
        return
    data = []
    for r in result["results"]["bindings"]:
        data.append({
            'run': maybe(r, 'run'),
            'epoch': maybe(r, 'epoch'),
            'start': maybe(r, 'start'),
            'end': maybe(r, 'end'),
        })
    if len(data) != 1:
        return None
    d = data[0]
    start_ts = parse_time_with_ms(d.get('start'))
    ended_ts = parse_time_with_ms(d.get('end')) if d.get('end') is not None else None
    run = OrchestratorRun(
            name=name,
            run=d.get('run'),
            epoch=int(d.get('epoch')),
            started=start_ts,
            ended=ended_ts)
    return run

def query_last_activity_by_project(name):
    ctx = {'project': name} 
    endpoint = get_graph_endpoint_query()
    result = queryFromTemplate(lastActivityForProject, ctx, endpoint=endpoint)
    if result is None:
        return
    data = []
    for r in result["results"]["bindings"]:
        data.append(maybe(r, 'act'))
    if len(data) != 1:
        print(data)
        raise ValueError("Expected a single result")
    return data[0]

def query_files_for_epoch(name):
    endpoint = get_graph_endpoint_query()
    annotations = get_annotation_endpoint_query()
    ctx = {'project': name, 'annotations': annotations, 'graph': endpoint}
    result = queryFromTemplate(filesForEpochRun, ctx, endpoint=endpoint)
    if result is None:
        return
    data = []
    for r in result["results"]["bindings"]:
        data.append({
           'location': maybe(r, 'location'),
           'checksum': maybe(r, 'checksum'),
           'keywords': maybe(r, 'keywords'),
           'ended': maybe(r, 'ended')
        })
    print(tabulate(
        data, showindex=True,
        headers={"location": "location", "checksum": "checksum", "keywords": "keywords", "ended": "ended"}))


def query_provenance_for_last_epoch(name, draw=False, target=None):
    endpoint = get_graph_endpoint_query()
    annotations = get_annotation_endpoint_query()
    ctx = {'benchmark': name,  'graph': endpoint, 'annotations': annotations}
    result = queryFromTemplate(provenanceForLastEpoch, ctx, endpoint=endpoint)
    if result is None:
        return
    data = []
    now = datetime.datetime.now()
    for r in result["results"]["bindings"]:
        data.append({
            'keywords': maybe(r, 'kw'),
            'ended': humanize.naturaldelta(now - parse_time(maybe(r, 'ended')[:-1])) + " ago",
            'input': maybe(r, 'inputfile').split('data/')[1],
            'output': maybe(r, 'outputfile').split('data/')[1],
            'activity': maybe(r, 'act').split('/')[-1][:8]
        })
    print(tabulate(
        data, showindex=True,
        headers={"keywords": "keywords", "input": "input", "output": "output", "activity": "activity"}))

    # TODO: presentation layer should be moved away from sparql module
    if draw:
        try:
            import networkx as nx
            import matplotlib.pyplot as plt
        except ImportError:
            print("[!] please install networkx and matplotlib")
            return

        edges = [(row['input'], row['output']) for row in data]
        G = nx.DiGraph()
        G.add_edges_from(edges)

        if target is None:
            plot_graph(G)
        else:
            plot_connected_component(G, target)

def maybe(d, var):
    _d = d.get(var)
    if _d is None:
        return None
    return _d.get('value')
