# pylint: skip-file
# type: ignore

# NOTE: This is stripped down version of
#           kubernetes/config/kube_config.py
#           kubernetes/client/configuration.py
#           kubernetes/config/dateutil.py
#       Removes the need to make kubernetes a dependency of mcli

#
# Copyright 2018 The Kubernetes Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import absolute_import

import atexit
import base64
import copy
import datetime
import json
import logging
import math
import multiprocessing
import os
import platform
import re
import subprocess
import sys
import tempfile
import time
from collections import namedtuple

import six
import urllib3
import yaml
from six.moves import http_client as httplib


class ConfigException(Exception):
    pass


class ExecProvider(object):
    """
    Implementation of the proposal for out-of-tree client
    authentication providers as described here --
    https://github.com/kubernetes/community/blob/master/contributors/design-proposals/auth/kubectl-exec-plugins.md

    Missing from implementation:

    * TLS cert support
    * caching
    """

    def __init__(self, exec_config, cwd):
        """
        exec_config must be of type ConfigNode because we depend on
        safe_get(self, key) to correctly handle optional exec provider
        config parameters.
        """
        for key in ['command', 'apiVersion']:
            if key not in exec_config:
                raise ConfigException('exec: malformed request. missing key \'%s\'' % key)
        self.api_version = exec_config['apiVersion']
        self.args = [exec_config['command']]
        if exec_config.safe_get('args'):
            self.args.extend(exec_config['args'])
        self.env = os.environ.copy()
        if exec_config.safe_get('env'):
            additional_vars = {}
            for item in exec_config['env']:
                name = item['name']
                value = item['value']
                additional_vars[name] = value
            self.env.update(additional_vars)

        self.cwd = cwd or None

    def run(self, previous_response=None):
        is_interactive = sys.stdout.isatty()
        kubernetes_exec_info = {
            'apiVersion': self.api_version,
            'kind': 'ExecCredential',
            'spec': {
                'interactive': is_interactive
            }
        }
        if previous_response:
            kubernetes_exec_info['spec']['response'] = previous_response
        self.env['KUBERNETES_EXEC_INFO'] = json.dumps(kubernetes_exec_info)
        process = subprocess.Popen(self.args,
                                   stdout=subprocess.PIPE,
                                   stderr=sys.stderr if is_interactive else subprocess.PIPE,
                                   stdin=sys.stdin if is_interactive else None,
                                   cwd=self.cwd,
                                   env=self.env,
                                   universal_newlines=True)
        (stdout, stderr) = process.communicate()
        exit_code = process.wait()
        if exit_code != 0:
            msg = 'exec: process returned %d' % exit_code
            stderr = stderr.strip()
            if stderr:
                msg += '. %s' % stderr
            raise ConfigException(msg)
        try:
            data = json.loads(stdout)
        except ValueError as de:
            raise ConfigException('exec: failed to decode process output: %s' % de)
        for key in ('apiVersion', 'kind', 'status'):
            if key not in data:
                raise ConfigException('exec: malformed response. missing key \'%s\'' % key)
        if data['apiVersion'] != self.api_version:
            raise ConfigException('exec: plugin api version %s does not match %s' %
                                  (data['apiVersion'], self.api_version))
        return data['status']


class Configuration(object):
    """NOTE: This class is auto generated by OpenAPI Generator

    Ref: https://openapi-generator.tech
    Do not edit the class manually.

    :param host: Base url
    :param api_key: Dict to store API key(s).
      Each entry in the dict specifies an API key.
      The dict key is the name of the security scheme in the OAS specification.
      The dict value is the API key secret.
    :param api_key_prefix: Dict to store API prefix (e.g. Bearer)
      The dict key is the name of the security scheme in the OAS specification.
      The dict value is an API key prefix when generating the auth data.
    :param username: Username for HTTP basic authentication
    :param password: Password for HTTP basic authentication
    :param discard_unknown_keys: Boolean value indicating whether to discard
      unknown properties. A server may send a response that includes additional
      properties that are not known by the client in the following scenarios:
      1. The OpenAPI document is incomplete, i.e. it does not match the server
         implementation.
      2. The client was generated using an older version of the OpenAPI document
         and the server has been upgraded since then.
      If a schema in the OpenAPI document defines the additionalProperties attribute,
      then all undeclared properties received by the server are injected into the
      additional properties map. In that case, there are undeclared properties, and
      nothing to discard.

    :Example:

    API Key Authentication Example.
    Given the following security scheme in the OpenAPI specification:
      components:
        securitySchemes:
          cookieAuth:         # name for the security scheme
            type: apiKey
            in: cookie
            name: JSESSIONID  # cookie name

    You can programmatically set the cookie:
      conf = client.Configuration(
        api_key={'cookieAuth': 'abc123'}
        api_key_prefix={'cookieAuth': 'JSESSIONID'}
      )
    The following cookie will be added to the HTTP request:
       Cookie: JSESSIONID abc123
    """

    _default = None

    def __init__(
        self,
        host="http://localhost",
        api_key=None,
        api_key_prefix=None,
        username=None,
        password=None,
        discard_unknown_keys=False,
    ):
        """Constructor
        """
        self.host = host
        """Default Base url
        """
        self.temp_folder_path = None
        """Temp file folder for downloading files
        """
        # Authentication Settings
        self.api_key = {}
        if api_key:
            self.api_key = api_key
        """dict to store API key(s)
        """
        self.api_key_prefix = {}
        if api_key_prefix:
            self.api_key_prefix = api_key_prefix
        """dict to store API prefix (e.g. Bearer)
        """
        self.refresh_api_key_hook = None
        """function hook to refresh API key if expired
        """
        self.username = username
        """Username for HTTP basic authentication
        """
        self.password = password
        """Password for HTTP basic authentication
        """
        self.discard_unknown_keys = discard_unknown_keys
        self.logger = {}
        """Logging Settings
        """
        self.logger["package_logger"] = logging.getLogger("client")
        self.logger["urllib3_logger"] = logging.getLogger("urllib3")
        self.logger_format = '%(asctime)s %(levelname)s %(message)s'
        """Log format
        """
        self.logger_stream_handler = None
        """Log stream handler
        """
        self.logger_file_handler = None
        """Log file handler
        """
        self.logger_file = None
        """Debug file location
        """
        self.debug = False
        """Debug switch
        """

        self.verify_ssl = True
        """SSL/TLS verification
           Set this to false to skip verifying SSL certificate when calling API
           from https server.
        """
        self.ssl_ca_cert = None
        """Set this to customize the certificate file to verify the peer.
        """
        self.cert_file = None
        """client certificate file
        """
        self.key_file = None
        """client key file
        """
        self.assert_hostname = None
        """Set this to True/False to enable/disable SSL hostname verification.
        """

        self.connection_pool_maxsize = multiprocessing.cpu_count() * 5
        """urllib3 connection pool's maximum number of connections saved
           per pool. urllib3 uses 1 connection as default value, but this is
           not the best value when you are making a lot of possibly parallel
           requests to the same host, which is often the case here.
           cpu_count * 5 is used as default value to increase performance.
        """

        self.proxy = None
        """Proxy URL
        """
        self.no_proxy = None
        """bypass proxy for host in the no_proxy list.
        """
        self.proxy_headers = None
        """Proxy headers
        """
        self.safe_chars_for_path_param = ''
        """Safe chars for path_param
        """
        self.retries = None
        """Adding retries to override urllib3 default value 3
        """
        # Disable client side validation
        self.client_side_validation = True

    def __deepcopy__(self, memo):
        cls = self.__class__
        result = cls.__new__(cls)
        memo[id(self)] = result
        for k, v in self.__dict__.items():
            if k not in ('logger', 'logger_file_handler'):
                setattr(result, k, copy.deepcopy(v, memo))
        # shallow copy of loggers
        result.logger = copy.copy(self.logger)
        # use setters to configure loggers
        result.logger_file = self.logger_file
        result.debug = self.debug
        return result

    @classmethod
    def set_default(cls, default):
        """Set default instance of configuration.

        It stores default configuration, which can be
        returned by get_default_copy method.

        :param default: object of Configuration
        """
        cls._default = copy.deepcopy(default)

    @classmethod
    def get_default_copy(cls):
        """Return new instance of configuration.

        This method returns newly created, based on default constructor,
        object of Configuration class or returns a copy of default
        configuration passed by the set_default method.

        :return: The configuration object.
        """
        if cls._default is not None:
            return copy.deepcopy(cls._default)
        return Configuration()

    @property
    def logger_file(self):
        """The logger file.

        If the logger_file is None, then add stream handler and remove file
        handler. Otherwise, add file handler and remove stream handler.

        :param value: The logger_file path.
        :type: str
        """
        return self.__logger_file

    @logger_file.setter
    def logger_file(self, value):
        """The logger file.

        If the logger_file is None, then add stream handler and remove file
        handler. Otherwise, add file handler and remove stream handler.

        :param value: The logger_file path.
        :type: str
        """
        self.__logger_file = value
        if self.__logger_file:
            # If set logging file,
            # then add file handler and remove stream handler.
            self.logger_file_handler = logging.FileHandler(self.__logger_file)
            self.logger_file_handler.setFormatter(self.logger_formatter)
            for _, logger in six.iteritems(self.logger):
                logger.addHandler(self.logger_file_handler)

    @property
    def debug(self):
        """Debug status

        :param value: The debug status, True or False.
        :type: bool
        """
        return self.__debug

    @debug.setter
    def debug(self, value):
        """Debug status

        :param value: The debug status, True or False.
        :type: bool
        """
        self.__debug = value
        if self.__debug:
            # if debug status is True, turn on debug logging
            for _, logger in six.iteritems(self.logger):
                logger.setLevel(logging.DEBUG)
            # turn on httplib debug
            httplib.HTTPConnection.debuglevel = 1
        else:
            # if debug status is False, turn off debug logging,
            # setting log level to default `logging.WARNING`
            for _, logger in six.iteritems(self.logger):
                logger.setLevel(logging.WARNING)
            # turn off httplib debug
            httplib.HTTPConnection.debuglevel = 0

    @property
    def logger_format(self):
        """The logger format.

        The logger_formatter will be updated when sets logger_format.

        :param value: The format string.
        :type: str
        """
        return self.__logger_format

    @logger_format.setter
    def logger_format(self, value):
        """The logger format.

        The logger_formatter will be updated when sets logger_format.

        :param value: The format string.
        :type: str
        """
        self.__logger_format = value
        self.logger_formatter = logging.Formatter(self.__logger_format)

    def get_api_key_with_prefix(self, identifier):
        """Gets API key (with prefix if set).

        :param identifier: The identifier of apiKey.
        :return: The token for api key authentication.
        """
        if self.refresh_api_key_hook is not None:
            self.refresh_api_key_hook(self)
        key = self.api_key.get(identifier)
        if key:
            prefix = self.api_key_prefix.get(identifier)
            if prefix:
                return "%s %s" % (prefix, key)
            else:
                return key

    def get_basic_auth_token(self):
        """Gets HTTP basic authentication header (string).

        :return: The token for basic HTTP authentication.
        """
        username = ""
        if self.username is not None:
            username = self.username
        password = ""
        if self.password is not None:
            password = self.password
        return urllib3.util.make_headers(basic_auth=username + ':' + password).get('authorization')

    def auth_settings(self):
        """Gets Auth Settings dict for api client.

        :return: The Auth Settings information dict.
        """
        auth = {}
        if 'authorization' in self.api_key:
            auth['BearerToken'] = {
                'type': 'api_key',
                'in': 'header',
                'key': 'authorization',
                'value': self.get_api_key_with_prefix('authorization')
            }
        return auth

    def to_debug_report(self):
        """Gets the essential information for debugging.

        :return: The report for debugging.
        """
        return "Python SDK Debug Report:\n"\
               "OS: {env}\n"\
               "Python Version: {pyversion}\n"\
               "Version of the API: release-1.26\n"\
               "SDK Package Version: 26.1.0".\
               format(env=sys.platform, pyversion=sys.version)

    def get_host_settings(self):
        """Gets an array of host settings

        :return: An array of host settings
        """
        return [{
            'url': "/",
            'description': "No description provided",
        }]

    def get_host_from_settings(self, index, variables=None):
        """Gets host URL based on the index and variables
        :param index: array index of the host settings
        :param variables: hash of variable and the corresponding value
        :return: URL based on host settings
        """
        variables = {} if variables is None else variables
        servers = self.get_host_settings()

        try:
            server = servers[index]
        except IndexError:
            raise ValueError("Invalid index {0} when selecting the host settings. "
                             "Must be less than {1}".format(index, len(servers)))

        url = server['url']

        # go through variables and replace placeholders
        for variable_name, variable in server['variables'].items():
            used_value = variables.get(variable_name, variable['default_value'])

            if 'enum_values' in variable \
                    and used_value not in variable['enum_values']:
                raise ValueError("The variable `{0}` in the host URL has invalid value "
                                 "{1}. Must be {2}.".format(variable_name, variables[variable_name],
                                                            variable['enum_values']))

            url = url.replace("{" + variable_name + "}", used_value)

        return url


class TimezoneInfo(datetime.tzinfo):

    def __init__(self, h, m):
        self._name = "UTC"
        if h != 0 and m != 0:
            self._name += "%+03d:%2d" % (h, m)
        self._delta = datetime.timedelta(hours=h, minutes=math.copysign(m, h))

    def utcoffset(self, dt):
        return self._delta

    def tzname(self, dt):
        return self._name

    def dst(self, dt):
        return datetime.timedelta(0)


UTC = TimezoneInfo(0, 0)


def format_rfc3339(date_time):
    if date_time.tzinfo is None:
        date_time = date_time.replace(tzinfo=UTC)
    date_time = date_time.astimezone(UTC)
    return date_time.strftime('%Y-%m-%dT%H:%M:%SZ')


MICROSEC_PER_SEC = 1000000

# ref https://www.ietf.org/rfc/rfc3339.txt
_re_rfc3339 = re.compile(
    r"(\d\d\d\d)-(\d\d)-(\d\d)"  # full-date
    r"[ Tt]"  # Separator
    r"(\d\d):(\d\d):(\d\d)([.,]\d+)?"  # partial-time
    r"([zZ ]|[-+]\d\d?:\d\d)?",  # time-offset
    re.VERBOSE + re.IGNORECASE)
_re_timezone = re.compile(r"([-+])(\d\d?):?(\d\d)?")


def parse_rfc3339(s):
    if isinstance(s, datetime.datetime):
        # no need to parse it, just make sure it has a timezone.
        if not s.tzinfo:
            return s.replace(tzinfo=UTC)
        return s
    groups = _re_rfc3339.search(s).groups()
    dt = [0] * 7
    for x in range(6):
        dt[x] = int(groups[x])
    us = 0
    if groups[6] is not None:
        partial_sec = float(groups[6].replace(",", "."))
        us = int(MICROSEC_PER_SEC * partial_sec)
    tz = UTC
    if groups[7] is not None and groups[7] != 'Z' and groups[7] != 'z':
        tz_groups = _re_timezone.search(groups[7]).groups()
        hour = int(tz_groups[1])
        minute = 0
        if tz_groups[0] == "-":
            hour *= -1
        if tz_groups[2]:
            minute = int(tz_groups[2])
        tz = TimezoneInfo(hour, minute)
    return datetime.datetime(year=dt[0],
                             month=dt[1],
                             day=dt[2],
                             hour=dt[3],
                             minute=dt[4],
                             second=dt[5],
                             microsecond=us,
                             tzinfo=tz)


EXPIRY_SKEW_PREVENTION_DELAY = datetime.timedelta(minutes=5)
KUBE_CONFIG_DEFAULT_LOCATION = os.environ.get('KUBECONFIG', '~/.kube/config')
ENV_KUBECONFIG_PATH_SEPARATOR = ';' if platform.system() == 'Windows' else ':'
_temp_files = {}


def _cleanup_temp_files():
    global _temp_files
    for temp_file in _temp_files.values():
        try:
            os.remove(temp_file)
        except OSError:
            pass
    _temp_files = {}


def _create_temp_file_with_content(content, temp_file_path=None):
    if len(_temp_files) == 0:
        atexit.register(_cleanup_temp_files)
    # Because we may change context several times, try to remember files we
    # created and reuse them at a small memory cost.
    content_key = str(content)
    if content_key in _temp_files:
        return _temp_files[content_key]
    if temp_file_path and not os.path.isdir(temp_file_path):
        os.makedirs(name=temp_file_path)
    fd, name = tempfile.mkstemp(dir=temp_file_path)
    os.close(fd)
    _temp_files[content_key] = name
    with open(name, 'wb') as fd:
        fd.write(content.encode() if isinstance(content, str) else content)
    return name


def _is_expired(expiry):
    return ((parse_rfc3339(expiry) - EXPIRY_SKEW_PREVENTION_DELAY) <= datetime.datetime.utcnow().replace(tzinfo=UTC))


class FileOrData(object):
    """Utility class to read content of obj[%data_key_name] or file's
     content of obj[%file_key_name] and represent it as file or data.
     Note that the data is preferred. The obj[%file_key_name] will be used iff
     obj['%data_key_name'] is not set or empty. Assumption is file content is
     raw data and data field is base64 string. The assumption can be changed
     with base64_file_content flag. If set to False, the content of the file
     will assumed to be base64 and read as is. The default True value will
     result in base64 encode of the file content after read."""

    def __init__(self,
                 obj,
                 file_key_name,
                 data_key_name=None,
                 file_base_path="",
                 base64_file_content=True,
                 temp_file_path=None):
        if not data_key_name:
            data_key_name = file_key_name + "-data"
        self._file = None
        self._data = None
        self._base64_file_content = base64_file_content
        self._temp_file_path = temp_file_path
        if not obj:
            return
        if data_key_name in obj:
            self._data = obj[data_key_name]
        elif file_key_name in obj:
            self._file = os.path.normpath(os.path.join(file_base_path, obj[file_key_name]))

    def as_file(self):
        """If obj[%data_key_name] exists, return name of a file with base64
        decoded obj[%data_key_name] content otherwise obj[%file_key_name]."""
        use_data_if_no_file = not self._file and self._data
        if use_data_if_no_file:
            if self._base64_file_content:
                if isinstance(self._data, str):
                    content = self._data.encode()
                else:
                    content = self._data
                self._file = _create_temp_file_with_content(base64.standard_b64decode(content), self._temp_file_path)
            else:
                self._file = _create_temp_file_with_content(self._data, self._temp_file_path)
        if self._file and not os.path.isfile(self._file):
            raise ConfigException("File does not exist: %s" % self._file)
        return self._file

    def as_data(self):
        """If obj[%data_key_name] exists, Return obj[%data_key_name] otherwise
        base64 encoded string of obj[%file_key_name] file content."""
        use_file_if_no_data = not self._data and self._file
        if use_file_if_no_data:
            with open(self._file) as f:
                if self._base64_file_content:
                    self._data = bytes.decode(base64.standard_b64encode(str.encode(f.read())))
                else:
                    self._data = f.read()
        return self._data


class CommandTokenSource(object):

    def __init__(self, cmd, args, tokenKey, expiryKey):
        self._cmd = cmd
        self._args = args
        if not tokenKey:
            self._tokenKey = '{.access_token}'
        else:
            self._tokenKey = tokenKey
        if not expiryKey:
            self._expiryKey = '{.token_expiry}'
        else:
            self._expiryKey = expiryKey

    def token(self):
        fullCmd = self._cmd + (" ") + " ".join(self._args)
        process = subprocess.Popen([self._cmd] + self._args,
                                   stdout=subprocess.PIPE,
                                   stderr=subprocess.PIPE,
                                   universal_newlines=True)
        (stdout, stderr) = process.communicate()
        exit_code = process.wait()
        if exit_code != 0:
            msg = 'cmd-path: process returned %d' % exit_code
            msg += "\nCmd: %s" % fullCmd
            stderr = stderr.strip()
            if stderr:
                msg += '\nStderr: %s' % stderr
            raise ConfigException(msg)
        try:
            data = json.loads(stdout)
        except ValueError as de:
            raise ConfigException('exec: failed to decode process output: %s' % de)
        A = namedtuple('A', ['token', 'expiry'])
        return A(token=data['credential']['access_token'], expiry=parse_rfc3339(data['credential']['token_expiry']))


class KubeConfigLoader(object):

    def __init__(self,
                 config_dict,
                 active_context=None,
                 get_google_credentials=None,
                 config_base_path="",
                 config_persister=None,
                 temp_file_path=None):

        if config_dict is None:
            raise ConfigException('Invalid kube-config. '
                                  'Expected config_dict to not be None.')
        elif isinstance(config_dict, ConfigNode):
            self._config = config_dict
        else:
            self._config = ConfigNode('kube-config', config_dict)

        self._current_context = None
        self._user = None
        self._cluster = None
        self.set_active_context(active_context)
        self._config_base_path = config_base_path
        self._config_persister = config_persister
        self._temp_file_path = temp_file_path

    def set_active_context(self, context_name=None):
        if context_name is None:
            context_name = self._config['current-context']
        self._current_context = self._config['contexts'].get_with_name(context_name)
        if (self._current_context['context'].safe_get('user') and self._config.safe_get('users')):
            user = self._config['users'].get_with_name(self._current_context['context']['user'], safe=True)
            if user:
                self._user = user['user']
            else:
                self._user = None
        else:
            self._user = None
        self._cluster = self._config['clusters'].get_with_name(self._current_context['context']['cluster'])['cluster']

    def _load_authentication(self):
        """Read authentication from kube-config user section if exists.

        This function goes through various authentication methods in user
        section of kube-config and stops if it finds a valid authentication
        method. The order of authentication methods is:

            1. auth-provider (gcp, azure, oidc)
            2. token field (point to a token file)
            3. exec provided plugin
            4. username/password
        """
        if not self._user:
            return
        if self._load_auth_provider_token():
            return
        if self._load_user_token():
            return
        if self._load_from_exec_plugin():
            return
        self._load_user_pass_token()

    def _load_auth_provider_token(self):
        if 'auth-provider' not in self._user:
            return
        provider = self._user['auth-provider']
        if 'name' not in provider:
            return
        if provider['name'] == 'gcp':
            return self._load_gcp_token(provider)
        if provider['name'] == 'azure':
            return self._load_azure_token(provider)
        if provider['name'] == 'oidc':
            return self._load_oid_token(provider)

    def _azure_is_expired(self, provider):
        expires_on = provider['config']['expires-on']
        if expires_on.isdigit():
            return int(expires_on) < time.time()
        else:
            exp_time = time.strptime(expires_on, '%Y-%m-%d %H:%M:%S.%f')
            return exp_time < time.gmtime()

    def _load_azure_token(self, provider):
        if 'config' not in provider:
            return
        if 'access-token' not in provider['config']:
            return
        if 'expires-on' in provider['config']:
            if self._azure_is_expired(provider):
                self._refresh_azure_token(provider['config'])
        self.token = 'Bearer %s' % provider['config']['access-token']
        return self.token

    def _refresh_azure_token(self, config):
        if 'adal' not in globals():
            raise ImportError('refresh token error, adal library not imported')

        tenant = config['tenant-id']
        authority = 'https://login.microsoftonline.com/{}'.format(tenant)
        context = adal.AuthenticationContext(authority, validate_authority=True, api_version='1.0')
        refresh_token = config['refresh-token']
        client_id = config['client-id']
        apiserver_id = '00000002-0000-0000-c000-000000000000'
        try:
            apiserver_id = config['apiserver-id']
        except ConfigException:
            # We've already set a default above
            pass
        token_response = context.acquire_token_with_refresh_token(refresh_token, client_id, apiserver_id)

        provider = self._user['auth-provider']['config']
        provider.value['access-token'] = token_response['accessToken']
        provider.value['expires-on'] = token_response['expiresOn']
        if self._config_persister:
            self._config_persister()

    def _load_gcp_token(self, provider):
        if (('config' not in provider) or ('access-token' not in provider['config']) or
            ('expiry' in provider['config'] and _is_expired(provider['config']['expiry']))):
            # token is not available or expired, refresh it
            self._refresh_gcp_token()

        self.token = "Bearer %s" % provider['config']['access-token']
        if 'expiry' in provider['config']:
            self.expiry = parse_rfc3339(provider['config']['expiry'])
        return self.token

    def _refresh_gcp_token(self):
        if 'config' not in self._user['auth-provider']:
            self._user['auth-provider'].value['config'] = {}
        provider = self._user['auth-provider']['config']
        credentials = self._get_google_credentials()
        provider.value['access-token'] = credentials.token
        provider.value['expiry'] = format_rfc3339(credentials.expiry)
        if self._config_persister:
            self._config_persister()

    def _load_oid_token(self, provider):
        if 'config' not in provider:
            return

        reserved_characters = frozenset(["=", "+", "/"])
        token = provider['config']['id-token']

        if any(char in token for char in reserved_characters):
            # Invalid jwt, as it contains url-unsafe chars
            return

        parts = token.split('.')
        if len(parts) != 3:  # Not a valid JWT
            return

        padding = (4 - len(parts[1]) % 4) * '='
        if len(padding) == 3:
            # According to spec, 3 padding characters cannot occur
            # in a valid jwt
            # https://tools.ietf.org/html/rfc7515#appendix-C
            return

        self.token = "Bearer %s" % provider['config']['id-token']

        return self.token

    def _load_from_exec_plugin(self):
        if 'exec' not in self._user:
            return
        try:
            base_path = self._get_base_path(self._cluster.path)
            status = ExecProvider(self._user['exec'], base_path).run()
            if 'token' in status:
                self.token = "Bearer %s" % status['token']
            elif 'clientCertificateData' in status:
                # https://kubernetes.io/docs/reference/access-authn-authz/authentication/#input-and-output-formats
                # Plugin has provided certificates instead of a token.
                if 'clientKeyData' not in status:
                    logging.error('exec: missing clientKeyData field in '
                                  'plugin output')
                    return None
                self.cert_file = FileOrData(status,
                                            None,
                                            data_key_name='clientCertificateData',
                                            file_base_path=base_path,
                                            base64_file_content=False,
                                            temp_file_path=self._temp_file_path).as_file()
                self.key_file = FileOrData(status,
                                           None,
                                           data_key_name='clientKeyData',
                                           file_base_path=base_path,
                                           base64_file_content=False,
                                           temp_file_path=self._temp_file_path).as_file()
            else:
                logging.error('exec: missing token or clientCertificateData '
                              'field in plugin output')
                return None
            if 'expirationTimestamp' in status:
                self.expiry = parse_rfc3339(status['expirationTimestamp'])
            return True
        except Exception as e:
            logging.error(str(e))

    def _load_user_token(self):
        base_path = self._get_base_path(self._user.path)
        token = FileOrData(self._user,
                           'tokenFile',
                           'token',
                           file_base_path=base_path,
                           base64_file_content=False,
                           temp_file_path=self._temp_file_path).as_data()
        if token:
            self.token = "Bearer %s" % token
            return True

    def _load_user_pass_token(self):
        if 'username' in self._user and 'password' in self._user:
            self.token = urllib3.util.make_headers(basic_auth=(self._user['username'] + ':' +
                                                               self._user['password'])).get('authorization')
            return True

    def _get_base_path(self, config_path):
        if self._config_base_path is not None:
            return self._config_base_path
        if config_path is not None:
            return os.path.abspath(os.path.dirname(config_path))
        return ""

    def _load_cluster_info(self):
        if 'server' in self._cluster:
            self.host = self._cluster['server'].rstrip('/')
            if self.host.startswith("https"):
                base_path = self._get_base_path(self._cluster.path)
                self.ssl_ca_cert = FileOrData(self._cluster,
                                              'certificate-authority',
                                              file_base_path=base_path,
                                              temp_file_path=self._temp_file_path).as_file()
                if 'cert_file' not in self.__dict__:
                    # cert_file could have been provided by
                    # _load_from_exec_plugin; only load from the _user
                    # section if we need it.
                    self.cert_file = FileOrData(self._user,
                                                'client-certificate',
                                                file_base_path=base_path,
                                                temp_file_path=self._temp_file_path).as_file()
                    self.key_file = FileOrData(self._user,
                                               'client-key',
                                               file_base_path=base_path,
                                               temp_file_path=self._temp_file_path).as_file()
        if 'insecure-skip-tls-verify' in self._cluster:
            self.verify_ssl = not self._cluster['insecure-skip-tls-verify']

    def _set_config(self, client_configuration):
        if 'token' in self.__dict__:
            client_configuration.api_key['authorization'] = self.token

            def _refresh_api_key(client_configuration):
                if ('expiry' in self.__dict__ and _is_expired(self.expiry)):
                    self._load_authentication()
                self._set_config(client_configuration)

            client_configuration.refresh_api_key_hook = _refresh_api_key
        # copy these keys directly from self to configuration object
        keys = ['host', 'ssl_ca_cert', 'cert_file', 'key_file', 'verify_ssl']
        for key in keys:
            if key in self.__dict__:
                setattr(client_configuration, key, getattr(self, key))

    def load_and_set(self, client_configuration):
        self._load_authentication()
        self._load_cluster_info()
        self._set_config(client_configuration)

    def list_contexts(self):
        return [context.value for context in self._config['contexts']]

    @property
    def current_context(self):
        return self._current_context.value


class ConfigNode(object):
    """Remembers each config key's path and construct a relevant exception
    message in case of missing keys. The assumption is all access keys are
    present in a well-formed kube-config."""

    def __init__(self, name, value, path=None):
        self.name = name
        self.value = value
        self.path = path

    def __contains__(self, key):
        return key in self.value

    def __len__(self):
        return len(self.value)

    def safe_get(self, key):
        if (isinstance(self.value, list) and isinstance(key, int) or key in self.value):
            return self.value[key]

    def __getitem__(self, key):
        v = self.safe_get(key)
        if v is None:
            raise ConfigException('Invalid kube-config file. Expected key %s in %s' % (key, self.name))
        if isinstance(v, dict) or isinstance(v, list):
            return ConfigNode('%s/%s' % (self.name, key), v, self.path)
        else:
            return v

    def get_with_name(self, name, safe=False):
        if not isinstance(self.value, list):
            raise ConfigException('Invalid kube-config file. Expected %s to be a list' % self.name)
        result = None
        for v in self.value:
            if 'name' not in v:
                raise ConfigException('Invalid kube-config file. '
                                      'Expected all values in %s list to have \'name\' key' % self.name)
            if v['name'] == name:
                if result is None:
                    result = v
                else:
                    raise ConfigException('Invalid kube-config file. '
                                          'Expected only one object with name %s in %s list' % (name, self.name))
        if result is not None:
            if isinstance(result, ConfigNode):
                return result
            else:
                return ConfigNode('%s[name=%s]' % (self.name, name), result, self.path)
        if safe:
            return None
        raise ConfigException('Invalid kube-config file. '
                              'Expected object with name %s in %s list' % (name, self.name))


class KubeConfigMerger:
    """Reads and merges configuration from one or more kube-config's.
    The propery `config` can be passed to the KubeConfigLoader as config_dict.

    It uses a path attribute from ConfigNode to store the path to kubeconfig.
    This path is required to load certs from relative paths.

    A method `save_changes` updates changed kubeconfig's (it compares current
    state of dicts with).
    """

    def __init__(self, paths):
        self.paths = []
        self.config_files = {}
        self.config_merged = None
        if hasattr(paths, 'read'):
            self._load_config_from_file_like_object(paths)
        else:
            self._load_config_from_file_path(paths)

    @property
    def config(self):
        return self.config_merged

    def _load_config_from_file_like_object(self, string):
        if hasattr(string, 'getvalue'):
            config = yaml.safe_load(string.getvalue())
        else:
            config = yaml.safe_load(string.read())

        if config is None:
            raise ConfigException('Invalid kube-config.')
        if self.config_merged is None:
            self.config_merged = copy.deepcopy(config)
        # doesn't need to do any further merging

    def _load_config_from_file_path(self, string):
        for path in string.split(ENV_KUBECONFIG_PATH_SEPARATOR):
            if path:
                path = os.path.expanduser(path)
                if os.path.exists(path):
                    self.paths.append(path)
                    self.load_config(path)
        self.config_saved = copy.deepcopy(self.config_files)

    def load_config(self, path):
        with open(path) as f:
            config = yaml.safe_load(f)

        if config is None:
            raise ConfigException('Invalid kube-config. '
                                  '%s file is empty' % path)

        if self.config_merged is None:
            config_merged = copy.deepcopy(config)
            for item in ('clusters', 'contexts', 'users'):
                config_merged[item] = []
            self.config_merged = ConfigNode(path, config_merged, path)
        for item in ('clusters', 'contexts', 'users'):
            self._merge(item, config.get(item, []) or [], path)
        self.config_files[path] = config

    def _merge(self, item, add_cfg, path):
        for new_item in add_cfg:
            for exists in self.config_merged.value[item]:
                if exists['name'] == new_item['name']:
                    break
            else:
                self.config_merged.value[item].append(ConfigNode('{}/{}'.format(path, new_item), new_item, path))

    def save_changes(self):
        for path in self.paths:
            if self.config_saved[path] != self.config_files[path]:
                self.save_config(path)
        self.config_saved = copy.deepcopy(self.config_files)

    def save_config(self, path):
        with open(path, 'w') as f:
            yaml.safe_dump(self.config_files[path], f, default_flow_style=False)


def _get_kube_config_loader(filename=None, config_dict=None, persist_config=False, **kwargs):
    if config_dict is None:
        kcfg = KubeConfigMerger(filename)
        if persist_config and 'config_persister' not in kwargs:
            kwargs['config_persister'] = kcfg.save_changes

        if kcfg.config is None:
            raise ConfigException('Invalid kube-config file. '
                                  'No configuration found.')
        return KubeConfigLoader(config_dict=kcfg.config, config_base_path=None, **kwargs)
    else:
        return KubeConfigLoader(config_dict=config_dict, config_base_path=None, **kwargs)


# USED BY m_interactive
def list_kube_config_contexts(config_file=None):

    if config_file is None:
        config_file = KUBE_CONFIG_DEFAULT_LOCATION

    loader = _get_kube_config_loader(filename=config_file)
    return loader.list_contexts(), loader.current_context


# USED BY m_interactive
def load_kube_config(config_file=None,
                     context=None,
                     client_configuration=None,
                     persist_config=True,
                     temp_file_path=None):
    """Loads authentication and cluster information from kube-config file
    and stores them in kubernetes.client.configuration.

    :param config_file: Name of the kube-config file.
    :param context: set the active context. If is set to None, current_context
        from config file will be used.
    :param client_configuration: The kubernetes.client.Configuration to
        set configs to.
    :param persist_config: If True, config file will be updated when changed
        (e.g GCP token refresh).
    :param temp_file_path: store temp files path.
    """

    if config_file is None:
        config_file = KUBE_CONFIG_DEFAULT_LOCATION

    loader = _get_kube_config_loader(filename=config_file,
                                     active_context=context,
                                     persist_config=persist_config,
                                     temp_file_path=temp_file_path)

    if client_configuration is None:
        config = type.__call__(Configuration)
        loader.load_and_set(config)
        Configuration.set_default(config)
    else:
        loader.load_and_set(client_configuration)
